# 과제 데이터1

```python
#로또 만들기

from random import random

list = []
for i in range(6):
    num = int(random()*45) + 1   #1~45 난수생성
    if num in list:
        num = int(random()*45) + 1 #리스트에 중복이면 다시 난수생성
    list.append(num)

    
list.sort()
print(list)
```





# 과제 데이터2

```python
1. 파일 내용을 읽은 후 상위 5개 데이터 확인
2. 배열 객체의 크기 확인 
3. 중복 지역 존재 여부 확인  
4. 2017년 수원시 인구의 합
5. 2017년 인구가 50만이상이 지역 출력
6. 2017년 경기도 전체 인구의 시별 인구 평균  

import pandas as pd
import numpy as np
file_path='./data/경기도인구데이터.csv'
df=pd.read_csv(file_path)

#상위 5개 데이터 확인
print(df[:5])

#배열 크기 확인
print(len(df))

#배열 크기 확인
print(df.shape)

#중복 지역 존재 여부 확인
check = df['구분'].is_unique
if check == True:
    print("중복안됨")
else :
    print("중복됨")

#2017년 수원시 인구 합
a = df.loc[0:3]
a['2017']
s=sum(a['2017'])

print('2017년 수원시 총 인구는 %d명'%s)

#2017년 인구가 50만 이상인 지역 출력
print('인구가 50만명 이상인 곳은', df[df['2017']>=500000]['구분'].values)

#2017년 경기도 전체 인구의 시별 인구 평균
c=pd.DataFrame(b.drop(['2007','2008', '2009','2010', '2011', '2012', '2013', '2014', '2015', '2016'], axis='columns'))
c.mean()
print('2017년 경기도 시별 인구 평균은 %d명'%c.mean())
```





# 과제 데이터3

```python
#기상자료개방포털 홈페이지 https://data.kma.go.kr 강수량, 전운량, 황사 발생일수 등 기상과 관련된 다양한 데이터가 존재
#상단 메뉴에서 기후통계분석 → 기후분석을 선택하고 
#조건별통계 페이지에서 기온 정보를 알고 싶은 지역과 기간을 설정하여
#‘지역별 기온 데이터’를 CSV 다운로드로 내려받습니다.
#pandas  라이브러리를 이용하여 다음 데이터를 찾는 코드를 작성하시오

#1번 서울지역의 2000년도~2018년도  날씨 데이터로부터  가장 기온이 낮았던 날짜와 기온 출력

#2번 서울지역의  2000년도~2018년도 날씨 데이터로부터  강수량이 가장 많았던 날짜와 기온 출력

#3번  서울지역의 2000년도~2018년도 날씨 데이터로부터 년도별 가장 높은 날의 기온과  년도별 가장 높은 날의 기온을 변화를 쉽게 파악할 수 있도록  시각화하시오(line chart)

#1번 서울지역의 2000년도~2018년도 날씨 데이터로부터 가장 기온이 낮았던 날짜와 기온 출력
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('C:/Users/student/data/서울지역 기온 데이터.csv',sep=",")
df_ns = df.drop(['지점', '평균기온(℃)','최고기온(℃)'], axis=1)
a=df_ns.sort_values(by='최저기온(℃)',ascending=True)


df_ns2 = df.drop(['지점', '평균기온(℃)','최저기온(℃)'], axis=1)

b=df_ns2.sort_values(by='최고기온(℃)',ascending=False)
print(a.head(1))
print(b.head(1))

#2번 서울지역의  2000년도~2018년도 날씨 데이터로부터  강수량이 가장 많았던 날짜와 강수량 출력
import pandas as pd
import matplotlib.pyplot as plt

df2 = pd.read_csv('C:/Users/student/data/서울지역 강수량 데이터.csv',sep=",")
df2_ns = df2.drop(['지점'], axis=1)
c=df2_ns.sort_values(by='강수량(mm)',ascending=False)

print(c.head(1))


#3번 서울지역의 2000년도~2018년도 날씨 데이터로부터 년도별 가장 높은 날의 기온과 년도별 가장 높은 날의 기온을 변화를 쉽게 파악할 수 있도록  시각화하시오(line chart)
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
from matplotlib import font_manager, rc
font_path='C:/Users/student/data/malgun.ttf'      
font_name= font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)



df4 = pd.read_csv('C:/Users/student/data/서울지역 기온 데이터.csv')
# 날짜 컬럼 년도까지 자르기
df4['날짜'] = df4['날짜'].str.slice(start=0, stop=4)
df4
#날짜 , 최저기온, 최고기온 컬럼 얻어오기
df4=df4.iloc[:,[0,3,4]]
df4
#년도별 최저기온, 최고기온 그룹
df_max=df4.groupby('날짜').max()
df_max


df_min=df4.groupby('날짜').min()
df_min

#년도를 index로 하여 최저기온, 최고기온 series데이터 만들기

minser = df_min.iloc[:,0]
maxser = df_max.iloc[:,1]
print(minser)
print(maxser)

plt.figure(figsize=(20, 15))
plt.title('서울시 최고 최저기온 비교')
plt.plot(minser.index, minser.values ,label='최저기온')
plt.plot(maxser.index, maxser.values,label='최고기온')


plt.xlabel('년도')
plt.ylabel('기온')
plt.legend()
plt.show()
```







# 과제 데이터4

```python
#게임 매상 감소 원인 분석

#1단계 : CSV 파일을 읽어들이기
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

dau = pd.read_csv("C:/Users/student/data/dau.csv").drop('app_name', axis = 1)
dpu = pd.read_csv("C:/Users/student/data/dpu.csv").drop('app_name', axis = 1)
install = pd.read_csv("C:/Users/student/data/install.csv").drop('app_name', axis = 1)

#2단계 :DAU 데이터에 Install 데이터를 결합시키기
df1.set_index('user_id', inplace = True)

df1 = pd.merge(dau, install, on = 'user_id', how = 'outer')

#3단계 : 1차결합된 데이터에 DPU 데이터를 결합시키기  
total_df = pd.merge(df1, dpu, on = ['user_id', 'log_date'], how = 'outer')

#4단계 : 비과금 유저의 과금액에 NaN을  0 대체해서  넣기  
total_df['payment'].fillna(0, inplace = True)

#5단계 : 월차 집계를 위한 월 항목 컬럼 추가  
total_df[['log_date', 'install_date']] = total_df[['log_date', 'install_date']].apply(pd.to_datetime)
total_df['month'] = total_df['log_date'].dt.to_period(freq = 'M')

#6단계 :추가된 월 항목 컬럼으로 그룹핑후 과금액 집계 (합계)
monthly_sum = total_df.groupby('month')['payment'].sum()
print(monthly_sum)

#7단계 :신규 유저인지 기존 유저인지 구분하는 항목의 새 컬럼변수 추가
total_df['new'] = 0
for k in range(len(total_df)):
    if total_df['log_date'][k] == total_df['install_date'][k] or pd.isnull(total_df['log_date'][k]):
        total_df['new'][k] = 'new'
    else:
        total_df['new'][k] = 'returning'

#8단계 :로그 날짜의 월과 유저타입으로 그룹핑해서 과금액 집계  (합계)
sum_df = total_df.groupby(['new', 'month'])['payment'].sum()
print(sum_df.unstack())

#9단계 : 그래프로 데이터 시각화

#그래프1(bar)
sum_df.unstack().plot(kind = 'bar', figsize = (10, 7))
plt.show()

graph_df = total_df.pivot_table(index='new', columns = 'log_date', values = 'payment').T

#그래프2(area)
from matplotlib import font_manager, rc
font_path='C:\Windows\Fonts\Malgun.ttf'    
font_name= font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)
graph_df.plot(kind = 'area', stacked = True, alpha = 0.2, figsize = (20, 10))  

plt.title('게임 내 결제액', size = 20)
plt.xlabel('날짜', size = 15)
plt.ylabel('결제액', size = 15)
plt.legend(loc = 'best', fontsize = 17)
plt.xticks(size = 10)
plt.yticks(size = 10)
plt.show()
```





# 과제 데이터5

```python
#1. 지하철 시간대별 이용 현황 데이터 시각화
import pandas as pd
df = pd.read_csv('C:/Users/student/data/subwaytime.csv', header=None).iloc[2:, 3:]
df.set_index(df.iloc[:,0], inplace=True)
df.drop(df.columns[[0,-1]], axis=1, inplace=True)
df.columns = [['%s-%s'%((i+4)%24, (i+5)%24) for i in range(24) for _ in (0,1)], ['승차', '하차']*24]
df = df.applymap(lambda x: int(x.replace(',', '')))
df_sum = df.sum()
order = df_sum.index.get_level_values(0).unique()
df_sum = df_sum.unstack().reindex(order)
df_sum['승차 누적'] = df_sum['승차'].cumsum()
df_sum['하차 누적'] = df_sum['하차'].cumsum()
df_sum['합계 누적'] = df_sum['승차 누적'] - df_sum['하차 누적']

df_sum['합계 누적'].plot(figsize=(10,4), kind='bar')
```

```python
#2. 출근 시간대 (7시 ~9시) 가장 많이 타고 내리는 역 찾기
import pandas as pd
df = pd.read_csv('C:/Users/student/data/subwaytime.csv', header=None).iloc[2:, 3:]
df.set_index(df.iloc[:,0], inplace=True)
df.drop(df.columns[[0,-1]], axis=1, inplace=True)
df.columns = [['%s-%s'%((i+4)%24, (i+5)%24) for i in range(24) for _ in (0,1)], ['승차', '하차']*24]
df = df.applymap(lambda x: int(x.replace(',', '')))
df_sum = df.sum()
order = df_sum.index.get_level_values(0).unique()
df_sum = df_sum.unstack().reindex(order)
df_sum['승차 누적'] = df_sum['승차'].cumsum()
df_sum['하차 누적'] = df_sum['하차'].cumsum()
df_sum['합계 누적'] = df_sum['승차 누적'] - df_sum['하차 누적']

df[['7-8', '8-9']].sum(level=1 ,axis=1).idxmax()
```

```python
#3. 밤 11시에 가장 많이 타는 역 찾기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('C:/Users/student/data/subwaytime.csv')
df.head()
df.info()
df.describe()
df.index
df.columns

df = df.drop (['사용월', '호선명', '역ID', '04:00:00~04:59:59', 'Unnamed: 5',
       '05:00:00~05:59:59', 'Unnamed: 7', '06:00:00~06:59:59', 'Unnamed: 9',
       '07:00:00~07:59:59', 'Unnamed: 11', '08:00:00~08:59:59', 'Unnamed: 13',
       '09:00:00~09:59:59', 'Unnamed: 15', '10:00:00~10:59:59', 'Unnamed: 17',
       '11:00:00~11:59:59', 'Unnamed: 19', '12:00:00~12:59:59', 'Unnamed: 21',
       '13:00:00~13:59:59', 'Unnamed: 23', '14:00:00~14:59:59', 'Unnamed: 25',
       '15:00:00~15:59:59', 'Unnamed: 27', '16:00:00~16:59:59', 'Unnamed: 29',
       '17:00:00~17:59:59', 'Unnamed: 31', '18:00:00~18:59:59', 'Unnamed: 33',
       '19:00:00~19:59:59', 'Unnamed: 35', '20:00:00~20:59:59', 'Unnamed: 37',
       '21:00:00~21:59:59', 'Unnamed: 39', '22:00:00~22:59:59', 'Unnamed: 41',
        'Unnamed: 43', '00:00:00~00:59:59', 'Unnamed: 45',
       '01:00:00~01:59:59', 'Unnamed: 47', '02:00:00~02:59:59', 'Unnamed: 49',
       '03:00:00~03:59:59', 'Unnamed: 51', 'Unnamed: 52'], axis=1)
df.columns=['지하철역', '승차인원']
df['승차인원'].replace('승차', np.nan, inplace=True) 
df.dropna(subset=['승차인원', '지하철역'], axis=0, inplace=True)
df['승차인원'] = df['승차인원'].astype('int')
dfs = df.sort_values(by='승차인원', ascending=False)
dfs
print(dfs.head(1))
```

```python
#4. titanic data set 을 decision tree로 분류 분석하시오
import pandas as pd
import seaborn as sns

df = sns.load_dataset('titanic')
#print(df.info())   #891개행, 15변수
#print(df.head())

#NaN 값이 많은 deck열(변수) 삭제
#embarked와 embark_town 열(변수)는 의미가 동일하므로 embark_town 열 삭제
ndf = df.drop (['embarked','who', 'adult_male','deck', 'embark_town','fare', 'class', 'alive', 'alone'], axis=1)
print(len(ndf))    #?
print(ndf.info())   #891개행, 15변수
print(ndf.head())
tmp = []
for each in ndf['sex']:
    if each == 'female':
        tmp.append(1)
    elif each == 'male':
        tmp.append(0)
    else:
        tmp.append(np.nan)

ndf['sex'] = tmp
ndf['sex'] = ndf['sex'].astype('float')

ndf = ndf[ndf['age'].notnull()]


X = ndf[ ['pclass', 'sex', 'age', 'sibsp', 'parch']]
Y = ndf['survived']

from sklearn import preprocessing 
X = preprocessing.StandardScaler().fit(X).transform(X)

# train:test(7:3)으로 데이터 분리
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=10)
print(X_train.shape)
print(X_test.shape)

#Decision Tree 분류 모델 생성
from sklearn import tree

tree_model = tree.DecisionTreeClassifier(criterion='entropy',  max_depth=5)
#tree_model = tree.DecisionTreeClassifier(criterion='gini',  max_depth=5)
tree_model.fit(X_train, Y_train)

y_predict = tree_model.predict(X_test)  #
print(y_predict[0:10])
print(Y_test.values[0:10])

from sklearn import metrics
tree_matrix = metrics.confusion_matrix(Y_test, y_predict)
print(tree_matrix)

tree_report = metrics.classification_report(Y_test, y_predict)
print(tree_report)
```



