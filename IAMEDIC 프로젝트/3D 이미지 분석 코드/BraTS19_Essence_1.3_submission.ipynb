{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readme\n",
    "We trid to test a variety of models to see their performance and applicability for medical services.\n",
    "\n",
    "This is simple copy of F. Wang's repository (github.com/woodywff/brats_2019).\n",
    "\n",
    "We updated the code to operate in **tensorflow 2.2 and windows10**.\n",
    "Some print() codes were added to see the process.\n",
    "\n",
    "InstanceNormalization is imported from tensorflow-addons instead of keras_contrib.\n",
    "\n",
    "During implementation we ran into 'dead kernel'(i.e. Windows fatal exception) when entering the validation steps, and it took us quite a long time to fix. (this problem also arise in ellisdg's code.)\n",
    "\n",
    "We found tensorflow using two differnt thread for training_data_generator and validation_data_generator  repectively. And the problem was raised by those threads accessing a single h5 data file.\n",
    "As a walkaround, we forced tensorflow to use only one thread and it worked.\n",
    "\n",
    "Having not much time for this work, we could only **train ~60 epochs** and could not apply trics such as crossvalidation or TTA (and we did not trained including validation image(20% of total train image), but the trained model was powerful enough to show that it is predicting quite precisely.\n",
    "\n",
    "With this seg_model_1.3, (which has almost same hyperparameters(e.g. patch size, depth, n_seg_levels) as original code), we eared **mean Dice-scores of 0.69, 0.87 and 0.75 in ET, WT, and TC** respectively (when we submitted prediction with validation dataset in (https://ipp.cbica.upenn.edu/).\n",
    "\n",
    "We expect the higher scores can be achieved when more dataset and augmentation is applied.\n",
    "Also, optimizing the model to reduce outlier predictions will be also effective considering **high median dice-scores(0.82, 0.90 and 0.85 respectively)** compared to mean dice-scores.\n",
    "\n",
    "FYI, We used AMD's Ryzen 3600X and Nvidia's RTX 2070 super (8GB VRAM) for training.\n",
    "\n",
    "We thank BraTS comunity memebers for their contribution in data preparation, code-sharing and all other major and minor works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:33:58.972573Z",
     "start_time": "2020-06-16T18:33:55.588510Z"
    }
   },
   "outputs": [],
   "source": [
    "# to prevent access violation error. (by train_generator and validation_generator in different threads)\n",
    "import tensorflow as tf\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "# tf.config.threading.set_intra_op_parallelism_threads(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:33:58.988588Z",
     "start_time": "2020-06-16T18:33:58.973573Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)\n",
    "\n",
    "# print('Compute dtype: %s' % policy.compute_dtype)\n",
    "# print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:33:59.004602Z",
     "start_time": "2020-06-16T18:33:58.989588Z"
    }
   },
   "outputs": [],
   "source": [
    "##### unet3d/metrics.py #####\n",
    "\n",
    "from functools import partial\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def dice_coefficient(y_true, y_pred, smooth=1.):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coefficient_loss(y_true, y_pred):\n",
    "    return -dice_coefficient(y_true, y_pred)\n",
    "\n",
    "def weighted_dice_coefficient(y_true, y_pred, axis=(-3, -2, -1), smooth=0.00001):\n",
    "    \"\"\"\n",
    "    Weighted dice coefficient. Default axis assumes a \"channels first\" data structure\n",
    "    :param smooth:\n",
    "    :param y_true:\n",
    "    :param y_pred:\n",
    "    :param axis:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return K.mean(2. * (K.sum(y_true * y_pred, axis=axis) + smooth/2)/\n",
    "                       (K.sum(y_true, axis=axis) + K.sum(y_pred,axis=axis) + smooth))\n",
    "\n",
    "def weighted_dice_coefficient_loss(y_true, y_pred):\n",
    "    return -weighted_dice_coefficient(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:33:59.036631Z",
     "start_time": "2020-06-16T18:33:59.005603Z"
    }
   },
   "outputs": [],
   "source": [
    "##### unet3d/model/unet.py #####\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, UpSampling3D, Activation, BatchNormalization,ReLU, PReLU, Conv3DTranspose\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# from unet3d.metrics import dice_coefficient_loss, get_label_dice_coefficient_function, dice_coefficient\n",
    "# from unet3d.metrics import dice_coefficient_loss, dice_coefficient\n",
    "\n",
    "K.set_image_data_format(\"channels_first\")\n",
    "\n",
    "def create_convolution_block(input_layer, n_filters, batch_normalization=False, kernel=(3, 3, 3), activation=ReLU,\n",
    "                             padding='same', strides=(1, 1, 1), instance_normalization=False):\n",
    "    \"\"\"\n",
    "    :param strides:\n",
    "    :param input_layer:\n",
    "    :param n_filters:\n",
    "    :param batch_normalization:\n",
    "    :param kernel:\n",
    "    :param activation: Keras activation layer to use. (default is 'relu')\n",
    "    :param padding:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(input_layer)\n",
    "    \n",
    "    if batch_normalization:\n",
    "        layer = BatchNormalization(axis=1)(layer)\n",
    "    elif instance_normalization:\n",
    "        try:\n",
    "            from tensorflow_addons.layers import InstanceNormalization\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Install tensorflow_addons in order to use instance normalization\")\n",
    "        layer = InstanceNormalization(axis=1)(layer)\n",
    "    return activation()(layer)\n",
    "    \n",
    "##### unet3d/model/isensee2017.py #####\n",
    "\n",
    "from functools import partial\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, Add, UpSampling3D, Activation, SpatialDropout3D, Conv3D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from .unet import create_convolution_block, concatenate\n",
    "# from ..metrics import weighted_dice_coefficient_loss, dice_coefficient\n",
    "\n",
    "create_convolution_block = partial(create_convolution_block, activation=LeakyReLU, instance_normalization=True)\n",
    "\n",
    "\n",
    "def isensee2017_model(input_shape=(4, 128, 128, 128), n_base_filters=16, depth=5, dropout_rate=0.3,\n",
    "                      n_segmentation_levels=3, n_labels=4, optimizer=Adam, initial_learning_rate=5e-4,\n",
    "                      loss_function=weighted_dice_coefficient_loss, activation_name=\"sigmoid\",metrics=dice_coefficient):\n",
    "    \"\"\"\n",
    "    This function builds a model proposed by Isensee et al. for the BRATS 2017 competition:\n",
    "    https://www.cbica.upenn.edu/sbia/Spyridon.Bakas/MICCAI_BraTS/MICCAI_BraTS_2017_proceedings_shortPapers.pdf\n",
    "\n",
    "    This network is highly similar to the model proposed by Kayalibay et al. \"CNN-based Segmentation of Medical\n",
    "    Imaging Data\", 2017: https://arxiv.org/pdf/1701.03056.pdf\n",
    "\n",
    "    :param input_shape:\n",
    "    :param n_base_filters:\n",
    "    :param depth:\n",
    "    :param dropout_rate:\n",
    "    :param n_segmentation_levels:\n",
    "    :param n_labels:\n",
    "    :param optimizer:\n",
    "    :param initial_learning_rate:\n",
    "    :param loss_function:\n",
    "    :param activation_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    current_layer = inputs\n",
    "    level_output_layers = list()\n",
    "    level_filters = list()\n",
    "    \n",
    "    for level_number in range(depth):\n",
    "        n_level_filters = (2**level_number) * n_base_filters #number of filters in each level(depth)\n",
    "        level_filters.append(n_level_filters) \n",
    "\n",
    "        if current_layer is inputs:\n",
    "            in_conv = create_convolution_block(current_layer, n_level_filters)\n",
    "        else:\n",
    "            in_conv = create_convolution_block(current_layer, n_level_filters, strides=(2, 2, 2)) #\n",
    "\n",
    "        context_output_layer = create_context_module(in_conv, n_level_filters, dropout_rate=dropout_rate)\n",
    "\n",
    "        summation_layer = Add()([in_conv, context_output_layer])\n",
    "        level_output_layers.append(summation_layer)\n",
    "        current_layer = summation_layer\n",
    "    \n",
    "    #J.Lee: print(level_filters)\n",
    "    \n",
    "    segmentation_layers = list()\n",
    "    for level_number in range(depth - 2, -1, -1):\n",
    "        up_sampling = create_up_sampling_module(current_layer, level_filters[level_number])\n",
    "        concatenation_layer = concatenate([level_output_layers[level_number], up_sampling], axis=1)\n",
    "        localization_output = create_localization_module(concatenation_layer, level_filters[level_number])\n",
    "        current_layer = localization_output\n",
    "        if level_number < n_segmentation_levels:\n",
    "            segmentation_layers.insert(0, Conv3D(n_labels, (1, 1, 1))(current_layer))\n",
    "\n",
    "    output_layer = None\n",
    "    for level_number in reversed(range(n_segmentation_levels)):\n",
    "        segmentation_layer = segmentation_layers[level_number]\n",
    "        if output_layer is None:\n",
    "            output_layer = segmentation_layer\n",
    "        else:\n",
    "            output_layer = Add()([output_layer, segmentation_layer])\n",
    "\n",
    "        if level_number > 0:\n",
    "            output_layer = UpSampling3D(size=(2, 2, 2))(output_layer)\n",
    "\n",
    "    activation_block = Activation(activation_name)(output_layer)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=activation_block)\n",
    "\n",
    "    if not isinstance(metrics, list):\n",
    "        metrics = [metrics]\n",
    "#     model.compile(optimizer=optimizer(lr=initial_learning_rate), loss=loss_function)        \n",
    "    model.compile(optimizer=optimizer(epsilon=1e-7, lr=initial_learning_rate), loss=loss_function, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_localization_module(input_layer, n_filters):\n",
    "    convolution1 = create_convolution_block(input_layer, n_filters)\n",
    "    convolution2 = create_convolution_block(convolution1, n_filters, kernel=(1, 1, 1))\n",
    "    return convolution2\n",
    "\n",
    "\n",
    "def create_up_sampling_module(input_layer, n_filters, size=(2, 2, 2)):\n",
    "    up_sample = UpSampling3D(size=size)(input_layer)\n",
    "    convolution = create_convolution_block(up_sample, n_filters)\n",
    "    return convolution\n",
    "\n",
    "\n",
    "def create_context_module(input_layer, n_level_filters, dropout_rate=0.3, data_format=\"channels_first\"):\n",
    "    convolution1 = create_convolution_block(input_layer=input_layer, n_filters=n_level_filters)\n",
    "    dropout = SpatialDropout3D(rate=dropout_rate, data_format=data_format)(convolution1)\n",
    "    convolution2 = create_convolution_block(input_layer=dropout, n_filters=n_level_filters)\n",
    "    return convolution2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:33:59.052645Z",
     "start_time": "2020-06-16T18:33:59.037632Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = isensee2017_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:33:59.196777Z",
     "start_time": "2020-06-16T18:33:59.192773Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T11:24:41.503349Z",
     "start_time": "2020-06-04T11:24:41.495361Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T09:42:14.759866Z",
     "start_time": "2020-06-04T09:42:14.744914Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:34:00.140649Z",
     "start_time": "2020-06-16T18:34:00.127637Z"
    }
   },
   "outputs": [],
   "source": [
    "config = dict()\n",
    "config[\"overwrite\"] = False \n",
    "config[\"all_modalities\"] = [\"t1\", \"t1ce\", \"flair\", \"t2\"]\n",
    "config[\"training_modalities\"] = config[\"all_modalities\"]\n",
    "\n",
    "config[\"image_shape\"] = (240,240,155)  # This determines what shape the images will be cropped/resampled to.\n",
    "config[\"patch_shape\"] = (128, 128, 128)     # switch to None to train on the whole image\n",
    "config[\"training_patch_start_offset\"] = (4, 4, 4)  # randomly offset the first patch index by up to this offset\n",
    "config[\"validation_patch_overlap\"] = 32\n",
    "\n",
    "config[\"data_file\"] = 'C:/IAMEDIC/Jaeho_code/data/data_N4_norm.h5' #os.path.abspath(\"../data/data.h5\")\n",
    "config[\"image_shape\"] = (240,240,155)\n",
    "config['mean_std_file'] =  'C:/IAMEDIC/Jaeho_code/data/mean_std.pkl' #os.path.abspath('../data/mean_std.pkl')\n",
    "\n",
    "config['val_data_file'] = 'C:/IAMEDIC/Jaeho_code/data/val_data.h5' #os.path.abspath(\"../data/val_data.h5\")\n",
    "config['val_predict_dir'] = 'C:/IAMEDIC/Jaeho_code/prediction/val_prediction' #os.path.abspath(\"val_prediction\")\n",
    "config['val_index_list'] = 'C:/IAMEDIC/Jaeho_code/data/val_index_list.pkl' #os.path.abspath('../data/val_index_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:34:00.571047Z",
     "start_time": "2020-06-16T18:34:00.554032Z"
    }
   },
   "outputs": [],
   "source": [
    "##### dev_tools/my_tools.py #####\n",
    "def print_red(something):\n",
    "    print(\"\\033[1;31m{}\\033[0m\".format(something))\n",
    "def pad_image(img_npy, target_image_shape):\n",
    "    '''\n",
    "    image: ndarray\n",
    "    target_image_shape: tuple or list\n",
    "    '''\n",
    "    source_shape = np.asarray(img_npy.shape)\n",
    "    target_image_shape = np.asarray(target_image_shape)\n",
    "    edge = (target_image_shape - source_shape)/2\n",
    "    pad_width = tuple((i,j) for i,j in zip(np.floor(edge).astype(int),np.ceil(edge).astype(int)))\n",
    "    padded_img = np.pad(img_npy,pad_width,'constant',constant_values=0)\n",
    "    return padded_img, pad_width\n",
    "\n",
    "def sec2hms(seconds):    \n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    d, h = divmod(h, 24)\n",
    "    return str(int(d))+' days, '+str(int(h))+' hours, '+str(int(m))+' mins, '+str(round(s,3))+' secs.'\n",
    "#     print(\"%d:%02d:%02d\" % (h, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:34:03.174930Z",
     "start_time": "2020-06-16T18:34:01.035469Z"
    }
   },
   "outputs": [],
   "source": [
    "##### brats_19/demo_task1/preprocess.py #####\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "from nipype.interfaces.ants import N4BiasFieldCorrection\n",
    "\n",
    "import pdb\n",
    "#from train_model import config\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "#from dev_tools.my_tools import print_red\n",
    "\n",
    "\n",
    "def get_image(subject_folder, name):\n",
    "    file_card = os.path.join(subject_folder, \"*\" + name + \".nii.gz\")\n",
    "    try:\n",
    "        return glob.glob(file_card)[0]\n",
    "    except IndexError:\n",
    "        raise RuntimeError(\"Could not find file matching {}\".format(file_card))\n",
    "    return\n",
    "\n",
    "def correct_bias(in_file, out_file, image_type=sitk.sitkFloat64):\n",
    "    \"\"\"\n",
    "    Corrects the bias using ANTs N4BiasFieldCorrection. If this fails, will then attempt to correct bias using SimpleITK\n",
    "    :param in_file: input file path\n",
    "    :param out_file: output file path\n",
    "    :return: file path to the bias corrected image\n",
    "    \"\"\"\n",
    "    correct = N4BiasFieldCorrection()\n",
    "    correct.inputs.input_image = in_file\n",
    "    correct.inputs.output_image = out_file\n",
    "    try:\n",
    "        done = correct.run()\n",
    "        return done.outputs.output_image\n",
    "    except IOError:\n",
    "        warnings.warn(RuntimeWarning(\"ANTs N4BIasFieldCorrection could not be found.\"\n",
    "                                     \"Will try using SimpleITK for bias field correction\"\n",
    "                                     \" which will take much longer. To fix this problem, add N4BiasFieldCorrection\"\n",
    "                                     \" to your PATH system variable. (example: EXPORT PATH=${PATH}:/path/to/ants/bin)\"))\n",
    "        input_image = sitk.ReadImage(in_file, image_type)\n",
    "        output_image = sitk.N4BiasFieldCorrection(input_image, input_image > 0)\n",
    "        sitk.WriteImage(output_image, out_file)\n",
    "        return os.path.abspath(out_file)\n",
    "\n",
    "\n",
    "def normalize_image(in_file, out_file, bias_correction=True):\n",
    "    if not os.path.exists(out_file):\n",
    "        if bias_correction:\n",
    "            correct_bias(in_file, out_file)\n",
    "        else:\n",
    "            shutil.copy(in_file, out_file)\n",
    "    return out_file\n",
    "\n",
    "def check_origin(in_file, in_file2):\n",
    "    \"\"\"\n",
    "    check origin of in_file1 and in_file2\n",
    "    if origins are not same, in_file1's origin will be overwritten with in_file2's origin\n",
    "    \"\"\"\n",
    "    image = sitk.ReadImage(in_file)\n",
    "    image2 = sitk.ReadImage(in_file2)\n",
    "    if not image.GetOrigin() == image2.GetOrigin(): \n",
    "        image.SetOrigin(image2.GetOrigin())\n",
    "        sitk.WriteImage(image, in_file)\n",
    "\n",
    "def convert_brats_folder(in_folder, out_folder, truth_name='seg', no_bias_correction_modalities=None, bias_correct=True):\n",
    "#     pdb.set_trace()\n",
    "    for name in config[\"all_modalities\"]:\n",
    "        try:\n",
    "            image_file = get_image(in_folder, name)\n",
    "        except RuntimeError as error:\n",
    "            if name == 't1ce':\n",
    "                print_red(in_folder)\n",
    "                image_file = get_image(in_folder, 't1Gd')\n",
    "                truth_name = \"GlistrBoost_ManuallyCorrected\"\n",
    "            else:\n",
    "                raise error\n",
    "\n",
    "        out_file = os.path.abspath(os.path.join(out_folder, name + \".nii.gz\"))\n",
    "        \n",
    "        if bias_correct:\n",
    "            perform_bias_correction = no_bias_correction_modalities and name not in no_bias_correction_modalities\n",
    "            normalize_image(image_file, out_file, bias_correction=perform_bias_correction)\n",
    "        else:\n",
    "            if not os.path.exists(out_file):\n",
    "                shutil.copy(image_file, out_file)\n",
    "    \n",
    "    # copy the truth file only for training dataset\n",
    "    if in_folder.split('/')[-2] == 'val':\n",
    "        return\n",
    "    try:\n",
    "        truth_file = get_image(in_folder, truth_name)\n",
    "    except RuntimeError:\n",
    "        truth_file = get_image(in_folder, truth_name.split(\"_\")[0])\n",
    "\n",
    "    out_file = os.path.abspath(os.path.join(out_folder, \"truth.nii.gz\"))\n",
    "    if not os.path.exists(out_file):\n",
    "        shutil.copy(truth_file, out_file)\n",
    "    check_origin(out_file, get_image(in_folder, config[\"all_modalities\"][0]))\n",
    "    \n",
    "    return\n",
    "\n",
    "def convert_brats_data(brats_folder, out_folder, bias_correct=True, overwrite=True, no_bias_correction_modalities=(\"flair\",)):\n",
    "    \"\"\"\n",
    "    Preprocesses the BRATS data and writes it to a given output folder. \n",
    "    :param brats_folder: folder containing the original brats data\n",
    "    :param out_folder: output folder to which the preprocessed data will be written\n",
    "    :param bias_correct: if False, just copy the original images to preprocessed folders.\n",
    "    :param overwrite: set to True in order to redo all the preprocessing\n",
    "    :param no_bias_correction_modalities: performing bias correction could reduce the signal of certain modalities. If\n",
    "    concerned about a reduction in signal for a specific modality, specify by including the given modality in a list\n",
    "    or tuple.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "#     pdb.set_trace()\n",
    "    \n",
    "    for subject_folder in tqdm(glob.glob(os.path.join(brats_folder, \"*\", \"*\"))):\n",
    "#         continue\n",
    "        if os.path.isdir(subject_folder):\n",
    "            subject = os.path.basename(subject_folder)\n",
    "            new_subject_folder = os.path.join(out_folder, os.path.basename(os.path.dirname(subject_folder)),\n",
    "                                              subject)\n",
    "            if not os.path.exists(new_subject_folder) or overwrite:\n",
    "                if not os.path.exists(new_subject_folder):\n",
    "                    os.makedirs(new_subject_folder)\n",
    "                convert_brats_folder(subject_folder, new_subject_folder,\n",
    "                                     no_bias_correction_modalities=no_bias_correction_modalities,bias_correct=bias_correct)\n",
    "        else:\n",
    "            print(subject_folder)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:34:03.333073Z",
     "start_time": "2020-06-16T18:34:03.175931Z"
    }
   },
   "outputs": [],
   "source": [
    "##### dev_tools/my_tools.py #####\n",
    "# from dev_tools.my_tools import minmax_normalize\n",
    "\n",
    "def minmax_normalize(img_npy):\n",
    "    '''\n",
    "    img_npy: ndarray\n",
    "    '''\n",
    "    min_value = np.min(img_npy)\n",
    "    max_value = np.max(img_npy)\n",
    "    return (img_npy - min_value)/(max_value - min_value)\n",
    "\n",
    "##### unet3d/normaize.py #####\n",
    "from progressbar import *\n",
    "\n",
    "def normalize_data_storage(data_storage, offset=0.1, mul_factor=100, save_file='../data/mean_std.pkl'):\n",
    "    '''\n",
    "    data_storage is modality_storage_list\n",
    "    1. -mean/std(all nonzero voxels(brain area) of all images for the same modality)\n",
    "    2. minmax(each image individually)\n",
    "    offset and mul_factor are used to make brain voxel distinct from background zero points.\n",
    "    '''\n",
    "#     pdb.set_trace()\n",
    "    print('normalize_data_storage...')\n",
    "    mean_std_values = {}\n",
    "    for modality_storage in data_storage:\n",
    "        means = []\n",
    "        pbar = ProgressBar().start()\n",
    "        print('calculate mean value...')\n",
    "        n_subs = modality_storage.shape[0]\n",
    "        for i in range(n_subs):\n",
    "            means.append(np.mean(np.ravel(modality_storage[i])[np.flatnonzero(modality_storage[i])]))\n",
    "            pbar.update(int(i*100/(n_subs-1)))\n",
    "        pbar.finish()\n",
    "        mean = np.mean(means)\n",
    "        mean_std_values[modality_storage.name + '_mean'] = mean \n",
    "        print('mean=',mean)\n",
    "        \n",
    "        std_means = []\n",
    "        pbar = ProgressBar().start()\n",
    "        print('calculate std value...')\n",
    "        for i in range(n_subs):\n",
    "            std_means.append(np.mean(np.power(np.ravel(modality_storage[i])[np.flatnonzero(modality_storage[i])]-mean,2)))\n",
    "            pbar.update(int(i*100/(n_subs-1)))\n",
    "        pbar.finish()\n",
    "        std = np.sqrt(np.mean(std_means))\n",
    "        mean_std_values[modality_storage.name + '_std'] = std\n",
    "        print('std=',std)\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "        for i in range(n_subs):\n",
    "            brain_index = np.nonzero(modality_storage[i])\n",
    "            temp_img = np.copy(modality_storage[i])\n",
    "            temp_img[brain_index] = (minmax_normalize((modality_storage[i][brain_index]-mean)/std) + offset)*mul_factor\n",
    "            modality_storage[i] = temp_img\n",
    "    print('normalization FINISHED')\n",
    "    with open(save_file,'wb') as f:\n",
    "        pickle.dump(mean_std_values,f)\n",
    "\n",
    "def normalize_data_storage_val(data_storage, offset=0.1, mul_factor=100, save_file='../data/mean_std.pkl'):\n",
    "    print('normalize validation data storage...')\n",
    "    if not os.path.exists(save_file):\n",
    "        print_red('There\\'s no mean_std.pkl file.')\n",
    "        return\n",
    "    with open(save_file,'rb') as f:\n",
    "        mean_std_values = pickle.load(f)\n",
    "    for modality_storage in data_storage:\n",
    "        n_subs = modality_storage.shape[0]\n",
    "        mean = mean_std_values[modality_storage.name + '_mean']\n",
    "        std = mean_std_values[modality_storage.name + '_std']\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "        for i in tqdm(range(n_subs)):\n",
    "            brain_index = np.nonzero(modality_storage[i])\n",
    "            temp_img = np.copy(modality_storage[i])\n",
    "            temp_img[brain_index] = (minmax_normalize((modality_storage[i][brain_index]-mean)/std) + offset)*mul_factor\n",
    "            modality_storage[i] = temp_img\n",
    "    print('normalization FINISHED')\n",
    "    return\n",
    "\n",
    "\n",
    "##### unet3d/data.py #####\n",
    "# uc: unchanged\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tables\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "# from .normalize import normalize_data_storage\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from dev_tools.my_tools import pad_image, print_red\n",
    "\n",
    "\n",
    "def create_data_file(out_file, n_samples, image_shape, modality_names):\n",
    "    '''\n",
    "    create storage in data.h5\n",
    "    \n",
    "    :param: out_file      : directory path of the h5 file to be generated\n",
    "    :param: n_samples     : number of samples. e.g: 1\n",
    "    :param: image_shape   : e.g: (155,240,240)\n",
    "    :param: modality_names: \n",
    "    :\n",
    "    '''\n",
    "#     pdb.set_trace()\n",
    "    hdf5_file = tables.open_file(out_file, mode='w')\n",
    "    filters = tables.Filters(complevel=5, complib='blosc')\n",
    "    modality_shape = tuple([0, 1] + list(image_shape)) # e.g. (0,1,155,240,240)\n",
    "    truth_shape =    tuple([0, 1] + list(image_shape)) # e.g. (0,1,155,240,240)\n",
    "    brain_width_shape = (0,2,3)\n",
    "    \n",
    "    \n",
    "    modality_storage_list = [hdf5_file.create_earray(hdf5_file.root, modality_name, tables.Float32Atom(), shape=modality_shape,\n",
    "                             filters=filters, expectedrows=n_samples) for modality_name in modality_names]\n",
    "    \n",
    "    truth_storage = hdf5_file.create_earray(hdf5_file.root, 'truth', tables.UInt8Atom(), shape=truth_shape,\n",
    "                                            filters=filters, expectedrows=n_samples)\n",
    "    \n",
    "    brain_width_storage = hdf5_file.create_earray(hdf5_file.root, 'brain_width', tables.UInt8Atom(), shape=brain_width_shape,\n",
    "                                            filters=filters, expectedrows=n_samples)\n",
    "    tumor_width_storage = hdf5_file.create_earray(hdf5_file.root, 'tumor_width', tables.UInt8Atom(), shape=brain_width_shape,\n",
    "                                            filters=filters, expectedrows=n_samples)\n",
    "    \n",
    "    return hdf5_file, [modality_storage_list, truth_storage, brain_width_storage, tumor_width_storage]\n",
    "\n",
    "\n",
    "\n",
    "def write_image_data_to_file(image_files, storage_list,\n",
    "                             image_shape, modality_names, truth_dtype=np.uint8, trivial_check = True):\n",
    "    '''\n",
    "    1. check the compliance of h5 files's modality order with modality_names argument.\n",
    "    2. \n",
    "    3. \n",
    "    4. \n",
    "    5. \n",
    "    :param: image_files   : \n",
    "    :param: storage_list  : \n",
    "    :param: image_shape   : \n",
    "    :param: modality_names: \n",
    "    :param: truth_dtype   : \n",
    "    :param: trivial_check : \n",
    "        to see if all images share the same affine info and pad_width, the incompliance file names \n",
    "        would be printed in red lines.\n",
    "        Also to check the order of modalities when added to the .h5\n",
    "    '''\n",
    "#     pdb.set_trace()\n",
    "\n",
    "    # 0.? affine settings ?: \n",
    "    # J.Lee: \n",
    "    # it seems affine_0 and save_affine could be assigned as argument in previous versions. \n",
    "    # that seems like the reason why 'trivial_check' in included in the code.\n",
    "    # affine argument seems to be required when 'augment=True'\n",
    "    affine_0 = None\n",
    "    save_affine = True\n",
    "    print('write_image_data_to_file...')\n",
    "    \n",
    "    #J.Lee_start\n",
    "    print(len(image_files))\n",
    "    print(f'image_files will be loaded from image_files \\n image_files[0]:{image_files[0]}')\n",
    "    #J.Lee_end\n",
    "    \n",
    "    # 1. check compliance of h5 files's modality order with modality_names argument.\n",
    "    for set_of_files in tqdm(image_files):\n",
    "        if trivial_check:\n",
    "            if not [os.path.basename(img_file).split('.')[0] for img_file in set_of_files] == modality_names + ['truth']:\n",
    "                print('wrong order of modalities')\n",
    "                print_red(image_nii_path)\n",
    "        subject_data = []\n",
    "        brain_widths = []\n",
    "        for i, image_nii_path in enumerate(set_of_files):\n",
    "            img = nib.load(image_nii_path)\n",
    "            affine = img.affine #J.Lee: all nii file has its affine value.\n",
    "            if affine_0 is None:\n",
    "                affine_0 = affine\n",
    "#             if trivial_check:\n",
    "#                 if np.sum(affine_0 - affine):\n",
    "#                     print('affine incompliance:')\n",
    "#                     print_red(image_nii_path)\n",
    "#                     save_affine = False\n",
    "            img_npy = img.get_fdata()\n",
    "            subject_data.append(img_npy)\n",
    "            \n",
    "            if i < len(set_of_files)-1: # we don't calculate brain_width for truth\n",
    "                brain_widths.append(cal_outline(img_npy))\n",
    "            else:\n",
    "                tumor_width = cal_outline(img_npy)\n",
    "                \n",
    "        start_edge = np.min(brain_widths,axis=0)[0]\n",
    "        end_edge = np.max(brain_widths,axis=0)[1]\n",
    "        brain_width = np.vstack((start_edge,end_edge))\n",
    "        \n",
    "        if add_data_to_storage(storage_list,\n",
    "                               subject_data, brain_width, tumor_width, truth_dtype, modality_names = modality_names):\n",
    "            print_red('modality_storage.name != modality_name')\n",
    "            print_red(set_of_files)\n",
    "    print('write_image_data_to_file...FINISHED')\n",
    "    if save_affine:\n",
    "        np.save('affine_N4_norm',affine_0)\n",
    "    return \n",
    "\n",
    "\n",
    "def cal_outline(img_npy):\n",
    "    '''\n",
    "    return a (2,3) array indicating the outline\n",
    "    J.Lee: i.e. highest and lowest coordinate of non-zero region will be ruturned.\n",
    "    '''\n",
    "    # J.Lee\n",
    "    # np.nonzero returns 3d coordinates with non-zero values.\n",
    "    # when (1,3),(1,2),(4,2) are returned, it means only (1,1,4) and (3,2,2) coordinates have non-zero values.\n",
    "    brain_index = np.asarray(np.nonzero(img_npy)) \n",
    "    start_edge = np.maximum(np.min(brain_index,axis=1)-1,0) #\n",
    "    end_edge = np.minimum(np.max(brain_index,axis=1)+1,img_npy.shape)\n",
    "    \n",
    "    return np.vstack((start_edge,end_edge))\n",
    "\n",
    "\n",
    "def add_data_to_storage(storage_list,\n",
    "                        subject_data, brain_width, tumor_width, truth_dtype, modality_names):\n",
    "#     pdb.set_trace()\n",
    "    modality_storage_list,truth_storage,brain_width_storage,tumor_width_storage = storage_list\n",
    "    for i in range(len(modality_names)):\n",
    "        if modality_storage_list[i].name != modality_names[i]:\n",
    "            print_red('modality_storage.name != modality_name')\n",
    "            return 1\n",
    "        modality_storage_list[i].append(np.asarray(subject_data[i])[np.newaxis][np.newaxis])\n",
    "    if truth_storage.name != 'truth':\n",
    "        print_red('truth_storage.name != truth')\n",
    "        return 1\n",
    "    truth_storage.append(np.asarray(subject_data[-1], dtype=truth_dtype)[np.newaxis][np.newaxis])\n",
    "    brain_width_storage.append(np.asarray(brain_width, dtype=truth_dtype)[np.newaxis])\n",
    "    tumor_width_storage.append(np.asarray(tumor_width, dtype=truth_dtype)[np.newaxis])\n",
    "    return 0\n",
    "\n",
    "def write_data_to_file(training_data_files, out_file, image_shape, modality_names, truth_dtype=np.uint8, subject_ids=None,\n",
    "                       normalize=True, mean_std_file='../data/mean_std.pkl'):\n",
    "#     pdb.set_trace()\n",
    "    n_samples = len(training_data_files)\n",
    "\n",
    "    hdf5_file, storage_list = create_data_file(out_file,\n",
    "                                               n_samples=n_samples,\n",
    "                                               image_shape=image_shape,\n",
    "                                               modality_names = modality_names)\n",
    "    modality_storage_list = storage_list[0]\n",
    "    write_image_data_to_file(training_data_files, \n",
    "                             storage_list,\n",
    "                             image_shape, truth_dtype=truth_dtype, modality_names = modality_names)\n",
    "    if subject_ids:\n",
    "        hdf5_file.create_array(hdf5_file.root, 'subject_ids', obj=subject_ids)\n",
    "    if normalize:\n",
    "        normalize_data_storage(modality_storage_list, save_file=mean_std_file)\n",
    "    hdf5_file.close()\n",
    "    return out_file\n",
    "\n",
    "\n",
    "def open_data_file(filename, readwrite=\"r\"):\n",
    "    return tables.open_file(filename, readwrite)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:34:03.349088Z",
     "start_time": "2020-06-16T18:34:03.334075Z"
    }
   },
   "outputs": [],
   "source": [
    "##### demo_task1/train_model.py #####\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "# from unet3d.data import write_data_to_file, open_data_file\n",
    "# from unet3d.generator import get_training_and_validation_generators\n",
    "# from unet3d.model import isensee2017_model\n",
    "# from unet3d.training import load_old_model, train_model\n",
    "import pdb\n",
    "import time\n",
    "#from dev_tools.my_tools import sec2hms\n",
    "\n",
    "def fetch_training_data_files(return_subject_ids=False):\n",
    "    import os\n",
    "    os.path.sep = '/'    \n",
    "    training_data_files = list()\n",
    "    subject_ids = list()\n",
    "    for subject_dir in glob.glob(os.path.join(\"C:/IAMEDIC/Jaeho_code/data\", \"preprocessed_N4\", \"*\", \"*\")):\n",
    "    #for subject_dir in glob.glob(\"C:/IAMEDIC/Jaeho_code/data/preprocessed/*/*\"): #J.Lee\n",
    "        #subject_dir = '/'.join(subject_dir.split('\\\\')) #J.Lee:\n",
    "        subject_ids.append(os.path.basename(subject_dir))\n",
    "        subject_files = list()\n",
    "        for modality in config[\"training_modalities\"] + [\"truth\"]:\n",
    "            subject_files.append(os.path.join(subject_dir, modality + \".nii.gz\"))\n",
    "        subject_files = ['/'.join(i.split('\\\\')) for i in subject_files] #J.Lee\n",
    "        training_data_files.append(tuple(subject_files))\n",
    "    if return_subject_ids:\n",
    "        return training_data_files, subject_ids\n",
    "    else:\n",
    "        return training_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T11:11:26.880461Z",
     "start_time": "2020-06-15T11:11:26.852435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('C:/IAMEDIC/Jaeho_code/data/preprocessed_N4/HGG/BraTS19_2013_10_1/t1.nii.gz', 'C:/IAMEDIC/Jaeho_code/data/preprocessed_N4/HGG/BraTS19_2013_10_1/t1ce.nii.gz', 'C:/IAMEDIC/Jaeho_code/data/preprocessed_N4/HGG/BraTS19_2013_10_1/flair.nii.gz', 'C:/IAMEDIC/Jaeho_code/data/preprocessed_N4/HGG/BraTS19_2013_10_1/t2.nii.gz', 'C:/IAMEDIC/Jaeho_code/data/preprocessed_N4/HGG/BraTS19_2013_10_1/truth.nii.gz')\n",
      "BraTS19_2013_10_1\n"
     ]
    }
   ],
   "source": [
    "print(fetch_training_data_files(return_subject_ids=True)[0][0])\n",
    "print(fetch_training_data_files(return_subject_ids=True)[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T02:29:21.497835Z",
     "start_time": "2020-06-09T02:29:21.437644Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:28:52.706447Z",
     "start_time": "2020-06-10T04:28:52.698439Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T11:11:27.320364Z",
     "start_time": "2020-06-15T11:11:27.308353Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "##### from preprocess.py #####\n",
    "\n",
    "\"\"\"\n",
    "cascade of functions:\n",
    "convert_brats_data -> convert_brats_folder\n",
    "\"\"\"\n",
    "# convert_brats_data('C:/IAMEDIC/Jaeho_code/data/original',\n",
    "#                    'C:/IAMEDIC/Jaeho_code/data/preprocessed',\n",
    "#                    no_bias_correction_modalities=['flair', 't1', 't1ce', 't2'] )\n",
    "\n",
    "##### demo_task1/train_model.py #####\n",
    "# from main()\n",
    "# convert input images into an hdf5 file\n",
    "\n",
    "\"\"\"\n",
    "J.Lee:\n",
    "cascade of functions:\n",
    "main() \n",
    "    -> fetch_training_data_files()\n",
    "    -> write_data_to_file()\n",
    "        -> create_data_file()\n",
    "            ->hdf5_file = tables.open_file()\n",
    "            ->hdf5_file.create_array()\n",
    "        -> write_image_data_to_file(): \n",
    "            -> add_data_to_storage()\n",
    "        -> if normalize: normalize_data_storage()\n",
    "\"\"\"\n",
    "\n",
    "# overwrite = True\n",
    "overwrite = False\n",
    "\n",
    "if overwrite or not os.path.exists(config[\"data_file\"]):\n",
    "    training_files, subject_ids = fetch_training_data_files(return_subject_ids=True)\n",
    "    #J.Lee_start\n",
    "    print(\"training_files[0]:\") \n",
    "    for i in training_files[0]: print(i)\n",
    "    print(\"training_files[-1]:\")\n",
    "    for i in training_files[-1]: print(i)\n",
    "    #J.Lee_end\n",
    "    write_data_to_file(training_files, \n",
    "                       config[\"data_file\"],\n",
    "                       image_shape=config[\"image_shape\"], \n",
    "                       modality_names = config['all_modalities'],\n",
    "                       subject_ids=subject_ids,\n",
    "                       mean_std_file = config['mean_std_file'],\n",
    "                       normalize = True )\n",
    "    \n",
    "# data_file_opened = open_data_file(config[\"data_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:34:09.880621Z",
     "start_time": "2020-06-16T18:34:09.872614Z"
    }
   },
   "outputs": [],
   "source": [
    "# from unet3d/utils.py\n",
    "\n",
    "def pickle_dump(item, out_file):\n",
    "    with open(out_file, \"wb\") as opened_file:\n",
    "        pickle.dump(item, opened_file)\n",
    "\n",
    "\n",
    "def pickle_load(in_file):\n",
    "    with open(in_file, \"rb\") as opened_file:\n",
    "        return pickle.load(opened_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:34:10.198413Z",
     "start_time": "2020-06-16T18:34:10.176890Z"
    }
   },
   "outputs": [],
   "source": [
    "# from unet3d/patches.py\n",
    "\n",
    "def compute_patch_indices(image_shape, patch_size, overlap, start=None):\n",
    "#     pdb.set_trace()\n",
    "    if isinstance(overlap, int):\n",
    "        overlap = np.asarray([overlap] * len(image_shape))\n",
    "    if start is None: # this method gets an even distribution of cubics as I wished\n",
    "        n_patches = np.ceil(image_shape / (patch_size - overlap))\n",
    "        overflow = (patch_size - overlap) * n_patches - image_shape + overlap\n",
    "        start = -np.ceil(overflow/2)\n",
    "    elif isinstance(start, int):\n",
    "        start = np.asarray([start] * len(image_shape))\n",
    "    stop = image_shape + start\n",
    "    step = patch_size - overlap\n",
    "    patches = get_set_of_patch_indices(start, stop, step)\n",
    "    # add the center cubic:\n",
    "    patches = np.vstack((patches, (image_shape - patch_size)//2))\n",
    "    return patches\n",
    "\n",
    "def compute_patch_indices_for_prediction(image_shape, patch_size, center_patch=True):\n",
    "#     pdb.set_trace()\n",
    "    pdb_set = False\n",
    "    if pdb_set:\n",
    "        if np.any(np.array(2*np.array(patch_size) - np.array(image_shape))<=0):\n",
    "            print_red('error patch: too large')\n",
    "        if  np.any(np.array(image_shape-patch_size)<=0):\n",
    "            print_red('error patch: too small')\n",
    "    start_2 = np.asarray(image_shape - patch_size)\n",
    "    start_2[start_2 < 0] = 0\n",
    "    patches = np.array([[0,         0,         0         ],\n",
    "                        [start_2[0],0,         0         ],\n",
    "                        [0,         start_2[1],0         ],\n",
    "                        [0,         0,         start_2[2]],\n",
    "                        [start_2[0],start_2[1],0         ],\n",
    "                        [start_2[0],start_2[1],start_2[2]],\n",
    "                        [start_2[0],0,         start_2[2]],\n",
    "                        [0,         start_2[1],start_2[2]]])\n",
    "    if center_patch:\n",
    "        patches = np.vstack((patches, (image_shape - patch_size)//2))\n",
    "    return patches\n",
    "\n",
    "\n",
    "def get_set_of_patch_indices(start, stop, step):\n",
    "#     pdb.set_trace()\n",
    "    return np.asarray(np.mgrid[start[0]:stop[0]:step[0], start[1]:stop[1]:step[1],\n",
    "                               start[2]:stop[2]:step[2]].reshape(3, -1).T, dtype=np.int)\n",
    "\n",
    "\n",
    "def get_random_nd_index(index_max):\n",
    "    return tuple([np.random.choice(index_max[index] + 1) for index in range(len(index_max))])\n",
    "\n",
    "\n",
    "def get_patch_from_3d_data(data, patch_shape, patch_index):\n",
    "    \"\"\"\n",
    "    Returns a patch from a numpy array.\n",
    "    :param data: numpy array from which to get the patch.\n",
    "    :param patch_shape: shape/size of the patch.\n",
    "    :param patch_index: corner index of the patch.\n",
    "    :return: numpy array take from the data with the patch shape specified.\n",
    "    \"\"\"\n",
    "    patch_index = np.asarray(patch_index, dtype=np.int16)\n",
    "    patch_shape = np.asarray(patch_shape)\n",
    "    image_shape = data.shape[-3:]\n",
    "    if np.any(patch_index < 0) or np.any((patch_index + patch_shape) > image_shape):\n",
    "        data, patch_index = fix_out_of_bound_patch_attempt(data, patch_shape, patch_index)\n",
    "    return data[..., patch_index[0]:patch_index[0]+patch_shape[0], patch_index[1]:patch_index[1]+patch_shape[1],\n",
    "                patch_index[2]:patch_index[2]+patch_shape[2]]\n",
    "\n",
    "def fix_out_of_bound_patch_attempt(data, patch_shape, patch_index, ndim=3):\n",
    "    \"\"\"\n",
    "    Pads the data and alters the patch index so that a patch will be correct.\n",
    "    :param data:\n",
    "    :param patch_shape:\n",
    "    :param patch_index:\n",
    "    :return: padded data, fixed patch index\n",
    "    \"\"\"\n",
    "    image_shape = data.shape[-ndim:]\n",
    "    pad_before = np.abs((patch_index < 0) * patch_index)\n",
    "    pad_after = np.abs(((patch_index + patch_shape) > image_shape) * ((patch_index + patch_shape) - image_shape))\n",
    "    pad_args = np.stack([pad_before, pad_after], axis=1)\n",
    "    if pad_args.shape[0] < len(data.shape):\n",
    "        pad_args = [[0, 0]] * (len(data.shape) - pad_args.shape[0]) + pad_args.tolist()\n",
    "#     data = np.pad(data, pad_args, mode=\"edge\")\n",
    "    data = np.pad(data, pad_args, 'constant',constant_values=0)\n",
    "    patch_index += pad_before\n",
    "    return data, patch_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:34:12.018065Z",
     "start_time": "2020-06-16T18:34:10.816975Z"
    }
   },
   "outputs": [],
   "source": [
    "##### from unet3d/augment.py #####\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn.image import new_img_like, resample_to_img\n",
    "\n",
    "def scale_image(image, scale_factor):\n",
    "    scale_factor = np.asarray(scale_factor)\n",
    "    new_affine = np.copy(image.affine)\n",
    "    new_affine[:3, :3] = image.affine[:3, :3] * scale_factor\n",
    "    new_affine[:, 3][:3] = image.affine[:, 3][:3] + (image.shape * np.diag(image.affine)[:3] * (1 - scale_factor)) / 2\n",
    "    return new_img_like(image, data=image.get_fdata(), affine=new_affine)\n",
    "\n",
    "\n",
    "def flip_image(image, axis):\n",
    "    try:\n",
    "        new_data = np.copy(image.get_fdata())\n",
    "        for axis_index in axis:\n",
    "            new_data = np.flip(new_data, axis=axis_index)\n",
    "    except TypeError:\n",
    "        new_data = np.flip(image.get_fdata(), axis=axis)\n",
    "    return new_img_like(image, data=new_data)\n",
    "\n",
    "\n",
    "def random_flip_dimensions(n_dimensions):\n",
    "    axis = list()\n",
    "    for dim in range(n_dimensions):\n",
    "        if random_boolean():\n",
    "            axis.append(dim)\n",
    "    return axis\n",
    "\n",
    "\n",
    "def random_scale_factor(n_dim=3, mean=1, std=0.25):\n",
    "    return np.random.normal(mean, std, n_dim)\n",
    "\n",
    "\n",
    "def random_boolean():\n",
    "    return np.random.choice([True, False])\n",
    "\n",
    "def distort_image(image, flip_axis=None, scale_factor=None):\n",
    "    if flip_axis:\n",
    "        image = flip_image(image, flip_axis)\n",
    "    if scale_factor is not None:\n",
    "        image = scale_image(image, scale_factor)\n",
    "    return image\n",
    "\n",
    "def get_image(data, affine, nib_class=nib.Nifti1Image):\n",
    "    return nib_class(dataobj=data, affine=affine)\n",
    "\n",
    "def augment_data(data, truth, affine, scale_deviation=None, flip=True):\n",
    "    n_dim = len(truth.shape)\n",
    "    if scale_deviation:\n",
    "        scale_factor = random_scale_factor(n_dim, std=scale_deviation)\n",
    "    else:\n",
    "        scale_factor = None\n",
    "    if flip:\n",
    "        flip_axis = random_flip_dimensions(n_dim)\n",
    "    else:\n",
    "        flip_axis = None\n",
    "    data_list = list()\n",
    "    for data_index in range(data.shape[0]):\n",
    "        image = get_image(data[data_index], affine)\n",
    "        data_list.append(resample_to_img(distort_image(image, flip_axis=flip_axis,\n",
    "                                                       scale_factor=scale_factor), image,\n",
    "                                         interpolation=\"nearest\").get_fdata())\n",
    "#                                          interpolation=\"continuous\").get_fdata())\n",
    "    data = np.asarray(data_list)\n",
    "    truth_image = get_image(truth, affine)\n",
    "    truth_data = resample_to_img(distort_image(truth_image, flip_axis=flip_axis, scale_factor=scale_factor),\n",
    "                                 truth_image, interpolation=\"nearest\").get_fdata()\n",
    "    return data, truth_data\n",
    "\n",
    "\n",
    "def generate_permutation_keys():\n",
    "    \"\"\"\n",
    "    This function returns a set of \"keys\" that represent the 48 unique rotations &\n",
    "    reflections of a 3D matrix.\n",
    "\n",
    "    Each item of the set is a tuple:\n",
    "    ((rotate_y, rotate_z), flip_x, flip_y, flip_z, transpose)\n",
    "\n",
    "    As an example, ((0, 1), 0, 1, 0, 1) represents a permutation in which the data is\n",
    "    rotated 90 degrees around the z-axis, then reversed on the y-axis, and then\n",
    "    transposed.\n",
    "\n",
    "    48 unique rotations & reflections:\n",
    "    https://en.wikipedia.org/wiki/Octahedral_symmetry#The_isometries_of_the_cube\n",
    "    \"\"\"\n",
    "    return set(itertools.product(\n",
    "        itertools.combinations_with_replacement(range(2), 2), range(2), range(2), range(2), range(2)))\n",
    "\n",
    "\n",
    "def random_permutation_key():\n",
    "    \"\"\"\n",
    "    Generates and randomly selects a permutation key. See the documentation for the\n",
    "    \"generate_permutation_keys\" function.\n",
    "    \"\"\"\n",
    "    return random.choice(list(generate_permutation_keys()))\n",
    "\n",
    "def permute_data(data, key):\n",
    "    \"\"\"\n",
    "    Permutes the given data according to the specification of the given key. Input data\n",
    "    must be of shape (n_modalities, x, y, z).\n",
    "\n",
    "    Input key is a tuple: (rotate_y, rotate_z), flip_x, flip_y, flip_z, transpose)\n",
    "\n",
    "    As an example, ((0, 1), 0, 1, 0, 1) represents a permutation in which the data is\n",
    "    rotated 90 degrees around the z-axis, then reversed on the y-axis, and then\n",
    "    transposed.\n",
    "    \"\"\"\n",
    "    data = np.copy(data)\n",
    "    (rotate_y, rotate_z), flip_x, flip_y, flip_z, transpose = key\n",
    "\n",
    "    if rotate_y != 0:\n",
    "        data = np.rot90(data, rotate_y, axes=(1, 3))\n",
    "    if rotate_z != 0:\n",
    "        data = np.rot90(data, rotate_z, axes=(2, 3))\n",
    "    if flip_x:\n",
    "        data = data[:, ::-1]\n",
    "    if flip_y:\n",
    "        data = data[:, :, ::-1]\n",
    "    if flip_z:\n",
    "        data = data[:, :, :, ::-1]\n",
    "    if transpose:\n",
    "        for i in range(data.shape[0]):\n",
    "            data[i] = data[i].T\n",
    "    return data\n",
    "\n",
    "def random_permutation_x_y(x_data, y_data):\n",
    "    \"\"\"\n",
    "    Performs random permutation on the data.\n",
    "    :param x_data: numpy array containing the data. Data must be of shape (n_modalities, x, y, z).\n",
    "    :param y_data: numpy array containing the data. Data must be of shape (n_modalities, x, y, z).\n",
    "    :return: the permuted data\n",
    "    \"\"\"\n",
    "    key = random_permutation_key()\n",
    "    return permute_data(x_data, key), permute_data(y_data, key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:34:12.606600Z",
     "start_time": "2020-06-16T18:34:12.520521Z"
    }
   },
   "outputs": [],
   "source": [
    "##### unet3d/generator.py #####\n",
    "\n",
    "import os\n",
    "import copy\n",
    "from random import shuffle\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from .utils import pickle_dump, pickle_load\n",
    "#from .patches import compute_patch_indices, get_random_nd_index, get_patch_from_3d_data, compute_patch_indices_for_prediction\n",
    "#from .augment import augment_data, random_permutation_x_y\n",
    "\n",
    "import pdb\n",
    "#from dev_tools.my_tools import print_red\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\"\"\"\n",
    "J.Lee:\n",
    "cascade of functions:\n",
    "get_training_and_validation_generators()\n",
    "    ->get_validation_split()\n",
    "        ->split_list()\n",
    "        ->pickle_dump(),pickle_load()\n",
    "    ->data_generator(tr)\n",
    "        ->if patch: create_patch_index_list()\n",
    "        ->while:\n",
    "            add_data()\n",
    "            if len(idx_list) == batch_size: yield convert_data()\n",
    "    ->data_generator(val) \n",
    "    ->get_number_of_patches(tr)\n",
    "    ->get_number_of_steps(tr)\n",
    "    ->get_number_of_patches(val)\n",
    "    ->get_number_of_steps(val)\n",
    "    \n",
    "    \n",
    "get_training_and_validation_generators\n",
    "    ->get_validation_split\n",
    "        ->split_list\n",
    "    ->data_generator\n",
    "        ->create_patch_index_list\n",
    "            ->get_random_nd_index\n",
    "            ->compute_patch_indices\n",
    "                ->get_set_of_patch_indices\n",
    "        ->while:\n",
    "          add_data\n",
    "            ->if patch_shape:\n",
    "              get_data_from_file\n",
    "                ->get_patch_from_3d_data\n",
    "                    ->fix_out_of_bound_patch_attempt\n",
    "            ->augment_data\n",
    "            ->random_permutation_x_y\n",
    "        ->if:\n",
    "          yield convert_data()\n",
    "    ->get_number_of_patches\n",
    "        ->if patch_shape: create_patch_index_list\n",
    "    ->get_number_of_steps\n",
    "    \n",
    "\"\"\"\n",
    "    \n",
    "\n",
    "def get_training_and_validation_generators(data_file, batch_size, n_labels, training_keys_file, validation_keys_file,\n",
    "                                           data_split=0.8, overwrite=False, labels=None, augment=False,\n",
    "                                           augment_flip=True, augment_distortion_factor=0.25, patch_shape=None,\n",
    "                                           validation_patch_overlap=0, training_patch_start_offset=None,\n",
    "                                           validation_batch_size=None, skip_blank=True, permute=False,num_model=1,\n",
    "                                           pred_specific=False, overlap_label=True,\n",
    "                                           for_final_val=False):\n",
    "#     pdb.set_trace()\n",
    "    if not validation_batch_size:\n",
    "        validation_batch_size = batch_size\n",
    "\n",
    "    training_list, validation_list = get_validation_split(data_file,\n",
    "                                                          data_split=data_split,\n",
    "                                                          overwrite=overwrite,\n",
    "                                                          training_file=training_keys_file,\n",
    "                                                          validation_file=validation_keys_file)\n",
    "    if for_final_val:\n",
    "        training_list = training_list + validation_list\n",
    "\n",
    "    training_generator = data_generator(data_file, training_list,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_labels=n_labels,\n",
    "                                        labels=labels,\n",
    "                                        augment=augment,\n",
    "                                        augment_flip=augment_flip,\n",
    "                                        augment_distortion_factor=augment_distortion_factor,\n",
    "                                        patch_shape=patch_shape,\n",
    "                                        patch_overlap=validation_patch_overlap,\n",
    "                                        patch_start_offset=training_patch_start_offset,\n",
    "                                        skip_blank=skip_blank,\n",
    "                                        permute=permute,\n",
    "                                        num_model=num_model,\n",
    "                                        pred_specific=pred_specific,\n",
    "                                        overlap_label=overlap_label)\n",
    "    \n",
    "    validation_generator = data_generator(data_file, validation_list,\n",
    "                                          batch_size=validation_batch_size,\n",
    "                                          n_labels=n_labels,\n",
    "                                          labels=labels,\n",
    "                                          patch_shape=patch_shape,\n",
    "                                          patch_overlap=validation_patch_overlap,\n",
    "                                          skip_blank=skip_blank,\n",
    "                                          num_model=num_model,\n",
    "                                          pred_specific=pred_specific,\n",
    "                                          overlap_label=overlap_label)\n",
    "\n",
    "    # Set the number of training and testing samples per epoch correctly\n",
    "#     pdb.set_trace()\n",
    "\n",
    "    #J.Lee:It takes long time. for testing, freeze and set num_training_steps as a small constant like 8. \n",
    "    if os.path.exists('num_patches_training_N4_norm_1.3.npy'):\n",
    "        num_patches_training = int(np.load('num_patches_training_N4_norm_1.3.npy'))\n",
    "    else:\n",
    "        num_patches_training = get_number_of_patches(data_file, training_list, patch_shape,\n",
    "                                                       skip_blank=skip_blank,\n",
    "                                                       patch_start_offset=training_patch_start_offset,\n",
    "                                                       patch_overlap=validation_patch_overlap,\n",
    "                                                       pred_specific=pred_specific)\n",
    "        np.save('num_patches_training_N4_norm_1.3', num_patches_training)\n",
    "    num_training_steps = get_number_of_steps(num_patches_training, batch_size)\n",
    "    print(\"Number of training steps in each epoch: \", num_training_steps)\n",
    "\n",
    "    if os.path.exists('num_patches_val_N4_norm_1.3.npy'):\n",
    "        num_patches_val = int(np.load('num_patches_val_N4_norm_1.3.npy'))\n",
    "    else:\n",
    "        num_patches_val = get_number_of_patches(data_file, validation_list, patch_shape,\n",
    "                                                 skip_blank=skip_blank,\n",
    "                                                 patch_overlap=validation_patch_overlap,\n",
    "                                                 pred_specific=pred_specific)\n",
    "        np.save('num_patches_val_N4_norm_1.3', num_patches_val)\n",
    "    num_validation_steps = get_number_of_steps(num_patches_val, validation_batch_size)\n",
    "    print(\"Number of validation steps in each epoch: \", num_validation_steps)\n",
    "\n",
    "    return training_generator, validation_generator, num_training_steps, num_validation_steps\n",
    "\n",
    "\n",
    "\n",
    "def get_number_of_steps(n_samples, batch_size):\n",
    "    if n_samples <= batch_size:\n",
    "        return n_samples\n",
    "    elif np.remainder(n_samples, batch_size) == 0:\n",
    "        return n_samples//batch_size\n",
    "    else:\n",
    "        return n_samples//batch_size + 1\n",
    "\n",
    "\n",
    "def get_validation_split(data_file, training_file, validation_file, data_split=0.8, overwrite=False):\n",
    "    '''\n",
    "    Splits the data into the training and validation indices list.\n",
    "    '''\n",
    "    if overwrite or not os.path.exists(training_file):\n",
    "        print(\"Creating validation split...\")\n",
    "        nb_samples = data_file.root.truth.shape[0]\n",
    "        sample_list = list(range(nb_samples))\n",
    "        training_list, validation_list = split_list(sample_list, split=data_split)\n",
    "        pickle_dump(training_list, training_file)\n",
    "        pickle_dump(validation_list, validation_file)\n",
    "        return training_list, validation_list\n",
    "    else:\n",
    "        print(\"Loading previous validation split...\")\n",
    "        return pickle_load(training_file), pickle_load(validation_file)\n",
    "\n",
    "\n",
    "def split_list(input_list, split=0.8, shuffle_list=True):\n",
    "    if shuffle_list:\n",
    "        shuffle(input_list)\n",
    "    n_training = int(len(input_list) * split)\n",
    "    training = input_list[:n_training]\n",
    "    testing = input_list[n_training:]\n",
    "    return training, testing\n",
    "\n",
    "\n",
    "def data_generator(data_file, index_list, batch_size=1, n_labels=1, labels=None, augment=False, augment_flip=True,\n",
    "                   augment_distortion_factor=0.25, patch_shape=None, patch_overlap=0, patch_start_offset=None,\n",
    "                   shuffle_index_list=True, skip_blank=True, permute=False, num_model=1, pred_specific=False,overlap_label=False):\n",
    "#     pdb.set_trace()\n",
    "\n",
    "    orig_index_list = index_list\n",
    "    while True:\n",
    "        x_list = list()\n",
    "        y_list = list()\n",
    "        if patch_shape:\n",
    "            index_list = create_patch_index_list(orig_index_list, data_file, patch_shape,\n",
    "                                                 patch_overlap, patch_start_offset,pred_specific=pred_specific)\n",
    "        else:\n",
    "            index_list = copy.copy(orig_index_list)\n",
    "\n",
    "        if shuffle_index_list:\n",
    "            shuffle(index_list)\n",
    "        while len(index_list) > 0:\n",
    "            index = index_list.pop()\n",
    "            add_data(x_list, y_list, data_file, index, augment=augment, augment_flip=augment_flip,\n",
    "                     augment_distortion_factor=augment_distortion_factor, patch_shape=patch_shape,\n",
    "                     skip_blank=skip_blank, permute=permute)\n",
    "            if len(x_list) == batch_size or (len(index_list) == 0 and len(x_list) > 0):\n",
    "                yield convert_data(x_list, y_list, n_labels=n_labels, labels=labels, num_model=num_model,overlap_label=overlap_label)\n",
    "#                 convert_data(x_list, y_list, n_labels=n_labels, labels=labels, num_model=num_model)\n",
    "                x_list = list()\n",
    "                y_list = list()\n",
    "\n",
    "\n",
    "\n",
    "def get_number_of_patches(data_file, index_list, patch_shape=None, patch_overlap=0, patch_start_offset=None,\n",
    "                          skip_blank=True,pred_specific=False):\n",
    "    if patch_shape:\n",
    "        index_list = create_patch_index_list(index_list, data_file, patch_shape, patch_overlap,\n",
    "                                             patch_start_offset,pred_specific=pred_specific)\n",
    "        count = 0\n",
    "        for index in tqdm(index_list):\n",
    "            x_list = list()\n",
    "            y_list = list()\n",
    "            add_data(x_list, y_list, data_file, index, skip_blank=skip_blank, patch_shape=patch_shape)\n",
    "            if len(x_list) > 0:\n",
    "                count += 1\n",
    "        return count\n",
    "    else:\n",
    "        return len(index_list)\n",
    "\n",
    "\n",
    "def create_patch_index_list(index_list, data_file, patch_shape, patch_overlap, patch_start_offset=None, pred_specific=False):\n",
    "    patch_index = list()\n",
    "    for index in index_list:\n",
    "        brain_width = data_file.root.brain_width[index]\n",
    "        image_shape = brain_width[1] - brain_width[0] + 1\n",
    "        if pred_specific:\n",
    "            patches = compute_patch_indices_for_prediction(image_shape, patch_shape)\n",
    "        else:\n",
    "            if patch_start_offset is not None:\n",
    "                random_start_offset = np.negative(get_random_nd_index(patch_start_offset))\n",
    "                patches = compute_patch_indices(image_shape, patch_shape, overlap=patch_overlap, start=random_start_offset)\n",
    "            else:\n",
    "                patches = compute_patch_indices(image_shape, patch_shape, overlap=patch_overlap)\n",
    "        patch_index.extend(itertools.product([index], patches))\n",
    "    return patch_index\n",
    "\n",
    "\n",
    "def add_data(x_list, y_list, data_file, index, augment=False, augment_flip=False, augment_distortion_factor=0.25,\n",
    "             patch_shape=False, skip_blank=True, permute=False):\n",
    "    '''\n",
    "    add qualified x,y to the generator list\n",
    "    '''\n",
    "#     pdb.set_trace()\n",
    "    data, truth = get_data_from_file(data_file, index, patch_shape=patch_shape)\n",
    "    \n",
    "    if np.sum(truth) == 0:\n",
    "        return\n",
    "    if augment:\n",
    "        affine = np.load('affine_N4_norm.npy')\n",
    "        data, truth = augment_data(data, truth, affine, flip=augment_flip, scale_deviation=augment_distortion_factor)\n",
    "\n",
    "    if permute:\n",
    "        if data.shape[-3] != data.shape[-2] or data.shape[-2] != data.shape[-1]:\n",
    "            raise ValueError(\"To utilize permutations, data array must be in 3D cube shape with all dimensions having \"\n",
    "                             \"the same length.\")\n",
    "        data, truth = random_permutation_x_y(data, truth[np.newaxis])\n",
    "    else:\n",
    "        truth = truth[np.newaxis]\n",
    "\n",
    "    if not skip_blank or np.any(truth != 0):\n",
    "        x_list.append(data)\n",
    "        y_list.append(truth)\n",
    "\n",
    "\n",
    "def get_data_from_file(data_file, index, patch_shape=None):\n",
    "#     pdb.set_trace()\n",
    "    if patch_shape:\n",
    "        index, patch_index = index\n",
    "        data, truth = get_data_from_file(data_file, index, patch_shape=None)\n",
    "        x = get_patch_from_3d_data(data, patch_shape, patch_index)\n",
    "        y = get_patch_from_3d_data(truth, patch_shape, patch_index)\n",
    "    else:\n",
    "        brain_width = data_file.root.brain_width[index]\n",
    "        x = np.array([modality_img[index,0,\n",
    "                                   brain_width[0,0]:brain_width[1,0]+1,\n",
    "                                   brain_width[0,1]:brain_width[1,1]+1,\n",
    "                                   brain_width[0,2]:brain_width[1,2]+1] \n",
    "                      for modality_img in [data_file.root.t1,\n",
    "                                           data_file.root.t1ce,\n",
    "                                           data_file.root.flair,\n",
    "                                           data_file.root.t2]])\n",
    "        y = data_file.root.truth[index, 0,\n",
    "                                 brain_width[0,0]:brain_width[1,0]+1,\n",
    "                                 brain_width[0,1]:brain_width[1,1]+1,\n",
    "                                 brain_width[0,2]:brain_width[1,2]+1]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def convert_data(x_list, y_list, n_labels=1, labels=None, num_model=1,overlap_label=False):\n",
    "#     pdb.set_trace()\n",
    "    x = np.asarray(x_list)\n",
    "    y = np.asarray(y_list)\n",
    "    if n_labels == 1:\n",
    "        y[y > 0] = 1\n",
    "    elif n_labels > 1:\n",
    "        if overlap_label:\n",
    "            y = get_multi_class_labels_overlap(y, n_labels=n_labels, labels=labels)\n",
    "        else:\n",
    "            y = get_multi_class_labels(y, n_labels=n_labels, labels=labels)\n",
    "    if num_model == 1:\n",
    "        return x, y\n",
    "    else:\n",
    "        return [x]*num_model, y\n",
    "\n",
    "\n",
    "def get_multi_class_labels_overlap(data, n_labels=3, labels=(1,2,4)):\n",
    "    \"\"\"\n",
    "    4: ET\n",
    "    1+4: TC\n",
    "    1+2+4: WT\n",
    "    \"\"\"\n",
    "#     pdb.set_trace()\n",
    "    new_shape = [data.shape[0], n_labels] + list(data.shape[2:])\n",
    "    y = np.zeros(new_shape, np.int8)\n",
    "    \n",
    "    y[:,0][np.logical_or(data[:,0] == 1,data[:,0] == 4)] = 1    #1\n",
    "    y[:,1][np.logical_or(data[:,0] == 1,data[:,0] == 2, data[:,0] == 4)] = 1 #2\n",
    "    y[:,2][data[:,0] == 4] = 1    #4\n",
    "    return y\n",
    "\n",
    "##### from ellisdg's unet3d/generator.py #####\n",
    "def get_multi_class_labels(data, n_labels, labels=None):\n",
    "    \"\"\"\n",
    "    Translates a label map into a set of binary labels.\n",
    "    :param data: numpy array containing the label map with shape: (n_samples, 1, ...).\n",
    "    :param n_labels: number of labels.\n",
    "    :param labels: integer values of the labels.\n",
    "    :return: binary numpy array of shape: (n_samples, n_labels, ...)\n",
    "    \"\"\"\n",
    "    new_shape = [data.shape[0], n_labels] + list(data.shape[2:])\n",
    "    y = np.zeros(new_shape, np.int8)\n",
    "    for label_index in range(n_labels):\n",
    "        if labels is not None:\n",
    "            y[:, label_index][data[:, 0] == labels[label_index]] = 1\n",
    "        else:\n",
    "            y[:, label_index][data[:, 0] == (label_index + 1)] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:34:15.294570Z",
     "start_time": "2020-06-16T18:34:15.272549Z"
    }
   },
   "outputs": [],
   "source": [
    "##### demo_task1/train_model.py #####\n",
    "\n",
    "config = dict()\n",
    "config[\"overwrite\"] = False              # To overwrite data.h5.\n",
    "# config[\"pool_size\"] = (2, 2, 2)          # pool size for the max pooling operations\n",
    "\n",
    "#J.lee: input_shape\n",
    "config[\"image_shape\"] = (128,128,64) #(240,240,155)  # This determines what shape the images will be cropped/resampled to.\n",
    "\n",
    "#J.lee: patching\n",
    "config[\"patch_shape\"] = (128, 128, 128)     # switch to None to train on the whole image\n",
    "config[\"training_patch_start_offset\"] = (4, 4, 4)  # randomly offset the first patch index by up to this offset\n",
    "config[\"validation_patch_overlap\"] = 32                # if > 0, during training, validation patches will be overlapping     \n",
    "config['pred_specific'] = False          # =True: To train with patching strategy specificly for prediction. \n",
    "config['center_patch'] = True            # To include the center patch in the patching strategy.\n",
    "\n",
    "#J.lee: batch\n",
    "config[\"batch_size\"] = 1\n",
    "config[\"validation_batch_size\"] = 1 # 2\n",
    "config[\"n_epochs\"] = 25 # 300\n",
    "\n",
    "#J.lee: paths for files.\n",
    "config[\"data_file\"] = 'C:/IAMEDIC/Jaeho_code/data/data_N4_norm.h5' # os.path.abspath(\"../data/data.h5\")\n",
    "# config[\"model_file\"] = 'C:/IAMEDIC/Jaeho_code/woodywff_seg_model.h5'# os.path.abspath(\"seg_model.h5\")\n",
    "config[\"model_file\"] = 'C:/IAMEDIC/Jaeho_code/seg_model_1.3.h5'# os.path.abspath(\"seg_model.h5\")\n",
    "config['mean_std_file'] = 'C:/IAMEDIC/Jaeho_code/data/mean_std.pkl' #os.path.abspath('../data/mean_std.pkl')\n",
    "\n",
    "#\n",
    "config[\"training_file\"] = \"C:/IAMEDIC/Jaeho_code/data/list_cv1.3_train.pkl\"\n",
    "config[\"validation_file\"] = \"C:/IAMEDIC/Jaeho_code/data/list_cv1.3_val.pkl\"\n",
    "\n",
    "\n",
    "config['for_final_val'] = True\n",
    "#--------------------------------------------------------------------------------\n",
    "config['logging_file'] = 'C:/IAMEDIC/Jaeho_code/training.log' #os.path.abspath('training.log')\n",
    "\n",
    "# truth.shape = (240,240,155) with value in [1,2,4], if 4 is on top of others or surrounded by others \n",
    "# config['overlap_label_generator'] = False\n",
    "# config['overlap_label_predict'] = False\n",
    "config['overlap_label_generator'] = True\n",
    "config['overlap_label_predict'] = True\n",
    "\n",
    "\n",
    "config[\"labels\"] = (1, 2, 4)             # the label numbers on the input image\n",
    "config[\"n_labels\"] = len(config[\"labels\"])\n",
    "config[\"all_modalities\"] = [\"t1\", \"t1ce\", \"flair\", \"t2\"]\n",
    "config[\"training_modalities\"] = config[\"all_modalities\"]  # change this if you want to only use some of the modalities\n",
    "config[\"nb_channels\"] = len(config[\"training_modalities\"])\n",
    "\n",
    "config[\"n_base_filters\"] = 16\n",
    "\n",
    "if \"patch_shape\" in config and config[\"patch_shape\"] is not None:\n",
    "    config[\"input_shape\"] = tuple([config[\"nb_channels\"]] + list(config[\"patch_shape\"]))\n",
    "else:\n",
    "    config[\"input_shape\"] = tuple([config[\"nb_channels\"]] + list(config[\"image_shape\"]))\n",
    "\n",
    "config[\"truth_channel\"] = config[\"nb_channels\"]\n",
    "config[\"deconvolution\"] = True           # if False, will use upsampling instead of deconvolution\n",
    "\n",
    "\n",
    "config[\"patience\"] = 5    # learning rate will be reduced after this many epochs if the validation loss is not improving\n",
    "config[\"early_stop\"] = 50  # training will be stopped after this many epochs without the validation loss improving\n",
    "config[\"initial_learning_rate\"] = 5e-4\n",
    "config[\"learning_rate_drop\"] = 0.5  # factor by which the learning rate will be reduced\n",
    "config[\"validation_split\"] = 0.8    # portion of the data that will be used for training\n",
    "\n",
    "config[\"flip\"] = False              # augments the data by randomly flipping an axis during\n",
    "# config[\"flip\"] = True\n",
    "# config[\"permute\"] = False\n",
    "config[\"permute\"] = True  # data shape must be a cube. Augments the data by permuting in various directions\n",
    "# config[\"distort\"] = None  # switch to None if you want no distortion\n",
    "config[\"distort\"] = 0.25\n",
    "config[\"augment\"] = config[\"flip\"] or config[\"distort\"]\n",
    "\n",
    "config[\"skip_blank\"] = True                           # if True, then patches without any target will be skipped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T11:11:35.672754Z",
     "start_time": "2020-06-15T11:11:35.658741Z"
    }
   },
   "outputs": [],
   "source": [
    "#J.Lee\n",
    "# print('n_train_steps:', n_train_steps)\n",
    "# print('n_validation_steps:', n_validation_steps)\n",
    "# print()\n",
    "# print('np.shape(next(train_generator)[0]):')\n",
    "# print(f'{np.shape(next(train_generator)[0])}')\n",
    "# print()\n",
    "# print('np.shape(next(validation_generator)[0]):')\n",
    "# print(f'{np.shape(next(validation_generator)[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:34:52.028676Z",
     "start_time": "2020-06-16T18:34:51.949604Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "import pdb\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow_addons.callbacks import TQDMProgressBar\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# from unet3d.metrics import dice_coefficient, dice_coefficient_loss, weighted_dice_coefficient_loss, weighted_dice_coefficient\n",
    "\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "##### unet3d/training.py\n",
    "def step_decay(epoch, initial_lrate, drop, epochs_drop):\n",
    "    return initial_lrate * math.pow(drop, math.floor((1+epoch)/float(epochs_drop)))\n",
    "\n",
    "def get_callbacks(model_file, initial_learning_rate=0.0001, learning_rate_drop=0.5, learning_rate_epochs=None,\n",
    "                  learning_rate_patience=50, logging_file=\"training.log\", verbosity=1,\n",
    "                  early_stopping_patience=None):\n",
    "    callbacks = list()\n",
    "    callbacks.append(ModelCheckpoint(model_file, save_best_only=True))\n",
    "    callbacks.append(CSVLogger(logging_file, append=True))\n",
    "    if learning_rate_epochs:\n",
    "        callbacks.append(LearningRateScheduler(partial(step_decay, initial_lrate=initial_learning_rate,\n",
    "                                                       drop=learning_rate_drop, epochs_drop=learning_rate_epochs)))\n",
    "    else:\n",
    "        callbacks.append(ReduceLROnPlateau(factor=learning_rate_drop, patience=learning_rate_patience,\n",
    "                                           verbose=verbosity))\n",
    "    if early_stopping_patience:\n",
    "        callbacks.append(EarlyStopping(verbose=verbosity, patience=early_stopping_patience))\n",
    "    callbacks.append(TQDMProgressBar())\n",
    "    return callbacks\n",
    "\n",
    "def load_old_model(model_file):\n",
    "#     pdb.set_trace()\n",
    "    print(\"Loading pre-trained model\")\n",
    "    custom_objects = {'dice_coefficient_loss': dice_coefficient_loss, 'dice_coefficient': dice_coefficient,\n",
    "                      'weighted_dice_coefficient': weighted_dice_coefficient,\n",
    "                      'weighted_dice_coefficient_loss': weighted_dice_coefficient_loss}\n",
    "    try:\n",
    "        from tensorflow_addons.layers import InstanceNormalization\n",
    "        custom_objects[\"InstanceNormalization\"] = InstanceNormalization\n",
    "    except ImportError:\n",
    "        pass\n",
    "    try:\n",
    "        return load_model(model_file, custom_objects=custom_objects)\n",
    "    except ValueError as error:\n",
    "        if 'InstanceNormalization' in str(error):\n",
    "            raise ValueError(str(error) + \"\\n\\nInstall tensorflow_addons in order to use instance normalization\\n\")\n",
    "        else:\n",
    "            raise error\n",
    "            \n",
    "def train_model(model, model_file, training_generator, validation_generator, steps_per_epoch, validation_steps,\n",
    "                initial_learning_rate=0.001, learning_rate_drop=0.5, learning_rate_epochs=None, n_epochs=500,\n",
    "                learning_rate_patience=20, early_stopping_patience=None, logging_file = 'training.log'):\n",
    "    model.fit(x=training_generator,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=n_epochs,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=validation_steps,\n",
    "                callbacks=get_callbacks(model_file,\n",
    "                                        initial_learning_rate=initial_learning_rate,\n",
    "                                        learning_rate_drop=learning_rate_drop,\n",
    "                                        learning_rate_epochs=learning_rate_epochs,\n",
    "                                        learning_rate_patience=learning_rate_patience,\n",
    "                                        logging_file = logging_file,\n",
    "                                        early_stopping_patience=early_stopping_patience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T11:11:41.228741Z",
     "start_time": "2020-06-15T11:11:41.218732Z"
    }
   },
   "outputs": [],
   "source": [
    "data_file_opened = open_data_file(config[\"data_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T06:41:30.758565Z",
     "start_time": "2020-06-14T06:41:28.292320Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model\n",
      "Loading previous validation split...\n",
      "Number of training steps in each epoch:  1660\n",
      "Number of validation steps in each epoch:  555\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##### demo_task1/train_model.py #####\n",
    "\n",
    "#from main()\n",
    "overwrite = False\n",
    "\n",
    "data_file_opened = open_data_file(config[\"data_file\"])\n",
    "\n",
    "if not overwrite and os.path.exists(config[\"model_file\"]):\n",
    "    model = load_old_model(config[\"model_file\"])\n",
    "else:\n",
    "    # instantiate new model\n",
    "    model = isensee2017_model(input_shape=config[\"input_shape\"], n_labels=config[\"n_labels\"],\n",
    "                              depth=5, #J.Lee added\n",
    "                              n_segmentation_levels = 3, #J.Lee added\n",
    "                              loss_function=weighted_dice_coefficient_loss,\n",
    "                              initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                              n_base_filters=config[\"n_base_filters\"])\n",
    "\n",
    "train_generator, validation_generator, n_train_steps, n_validation_steps = get_training_and_validation_generators(\n",
    "    data_file_opened,\n",
    "    batch_size= config[\"batch_size\"],\n",
    "    data_split= config[\"validation_split\"],\n",
    "    overwrite= False, #overwrite,\n",
    "    validation_keys_file=config[\"validation_file\"],\n",
    "    training_keys_file=config[\"training_file\"],\n",
    "    n_labels=config[\"n_labels\"],\n",
    "    labels=config[\"labels\"],\n",
    "    patch_shape=config[\"patch_shape\"],\n",
    "    validation_batch_size=config[\"validation_batch_size\"],\n",
    "    validation_patch_overlap=config[\"validation_patch_overlap\"],\n",
    "    training_patch_start_offset=config[\"training_patch_start_offset\"],\n",
    "    permute=config[\"permute\"],\n",
    "    augment=config[\"augment\"],\n",
    "    #skip_blank=config[\"skip_blank\"],\n",
    "    #augment_flip=config[\"flip\"],\n",
    "    augment_distortion_factor=config[\"distort\"],\n",
    "    #pred_specific=config['pred_specific'],\n",
    "    #overlap_label=config['overlap_label_generator'],\n",
    "    #for_final_val=config['for_final_val']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T08:25:06.717952Z",
     "start_time": "2020-06-13T08:25:06.702939Z"
    }
   },
   "outputs": [],
   "source": [
    "# not overwrite and os.path.exists('C:\\IAMEDIC\\Jaeho_code\\woodywff_seg_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T00:37:26.996624Z",
     "start_time": "2020-06-13T08:25:06.719954Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2eb5629bee486fbd3ebd77c4f858d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=25.0, style=Progr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd4849cb10a41f293107b7f1550d55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.3391 - dice_coefficient: 0.3839\n",
      "1660/1660 [==============================] - 2341s 1s/step - loss: -0.3391 - dice_coefficient: 0.3839 - val_loss: -0.4123 - val_dice_coefficient: 0.4803 - lr: 5.0000e-04\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f42f8e570f45edb43b829e9948b77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.4656 - dice_coefficient: 0.5419\n",
      "1660/1660 [==============================] - 2338s 1s/step - loss: -0.4656 - dice_coefficient: 0.5419 - val_loss: -0.4689 - val_dice_coefficient: 0.5204 - lr: 5.0000e-04\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62372704462b4106afc183c1460f5dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.4914 - dice_coefficient: 0.5736\n",
      "1660/1660 [==============================] - 2334s 1s/step - loss: -0.4914 - dice_coefficient: 0.5736 - val_loss: -0.4904 - val_dice_coefficient: 0.5575 - lr: 5.0000e-04\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0b445828954132890387b4b609fda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5017 - dice_coefficient: 0.5944\n",
      "1660/1660 [==============================] - 2327s 1s/step - loss: -0.5017 - dice_coefficient: 0.5944 - val_loss: -0.5006 - val_dice_coefficient: 0.5685 - lr: 5.0000e-04\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31f97d6925b4227903377bcbda1437d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5261 - dice_coefficient: 0.6239\n",
      "1660/1660 [==============================] - 2343s 1s/step - loss: -0.5261 - dice_coefficient: 0.6239 - val_loss: -0.4944 - val_dice_coefficient: 0.5599 - lr: 5.0000e-04\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc1d5e3c1034e78a54e19aef05021e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5151 - dice_coefficient: 0.6188\n",
      "1660/1660 [==============================] - 2335s 1s/step - loss: -0.5151 - dice_coefficient: 0.6188 - val_loss: -0.5158 - val_dice_coefficient: 0.5911 - lr: 5.0000e-04\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d61066d1a0418b9acf020cf54443c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5308 - dice_coefficient: 0.6290\n",
      "1660/1660 [==============================] - 2323s 1s/step - loss: -0.5308 - dice_coefficient: 0.6290 - val_loss: -0.5074 - val_dice_coefficient: 0.5957 - lr: 5.0000e-04\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e8d8c5808d4e19b047bf4e003273bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5339 - dice_coefficient: 0.6362\n",
      "1660/1660 [==============================] - 2325s 1s/step - loss: -0.5339 - dice_coefficient: 0.6362 - val_loss: -0.5202 - val_dice_coefficient: 0.5878 - lr: 5.0000e-04\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bd2f4dac5349e0bfc8e5c7fcb70177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5481 - dice_coefficient: 0.6487\n",
      "1660/1660 [==============================] - 2341s 1s/step - loss: -0.5481 - dice_coefficient: 0.6487 - val_loss: -0.5332 - val_dice_coefficient: 0.6101 - lr: 5.0000e-04\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9edd99619f4c77b0f9171b5dfcf90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5480 - dice_coefficient: 0.6545\n",
      "1660/1660 [==============================] - 2330s 1s/step - loss: -0.5480 - dice_coefficient: 0.6545 - val_loss: -0.5296 - val_dice_coefficient: 0.6014 - lr: 5.0000e-04\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171afcd5efbf46deb69a6a7207d8ce78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5467 - dice_coefficient: 0.6493\n",
      "1660/1660 [==============================] - 2322s 1s/step - loss: -0.5467 - dice_coefficient: 0.6493 - val_loss: -0.5218 - val_dice_coefficient: 0.5773 - lr: 5.0000e-04\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3c5bb0f65d4dcfb188a2f405fe3fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5615 - dice_coefficient: 0.6632\n",
      "1660/1660 [==============================] - 2333s 1s/step - loss: -0.5615 - dice_coefficient: 0.6632 - val_loss: -0.5309 - val_dice_coefficient: 0.6037 - lr: 5.0000e-04\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d76bb3eec004c0a8cb3ba622ba635ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5490 - dice_coefficient: 0.6513\n",
      "1660/1660 [==============================] - 2328s 1s/step - loss: -0.5490 - dice_coefficient: 0.6513 - val_loss: -0.5359 - val_dice_coefficient: 0.5994 - lr: 5.0000e-04\n",
      "Epoch 14/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c6c2c6c8884895bbf9ce9193c20c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5604 - dice_coefficient: 0.6600\n",
      "1660/1660 [==============================] - 2319s 1s/step - loss: -0.5604 - dice_coefficient: 0.6600 - val_loss: -0.5446 - val_dice_coefficient: 0.6238 - lr: 5.0000e-04\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477405ef73fe4a39afb89cbde327b8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5646 - dice_coefficient: 0.6791\n",
      "1660/1660 [==============================] - 2333s 1s/step - loss: -0.5646 - dice_coefficient: 0.6791 - val_loss: -0.5544 - val_dice_coefficient: 0.6446 - lr: 5.0000e-04\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79288520d956444ebca526fafb2cffea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5692 - dice_coefficient: 0.6780\n",
      "1660/1660 [==============================] - 2332s 1s/step - loss: -0.5692 - dice_coefficient: 0.6780 - val_loss: -0.5424 - val_dice_coefficient: 0.6142 - lr: 5.0000e-04\n",
      "Epoch 17/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d403c32ce2e44406a09558b319447e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5749 - dice_coefficient: 0.6868\n",
      "1660/1660 [==============================] - 2329s 1s/step - loss: -0.5749 - dice_coefficient: 0.6868 - val_loss: -0.5203 - val_dice_coefficient: 0.5772 - lr: 5.0000e-04\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef669e212f24e81a65dde97d25b265e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5722 - dice_coefficient: 0.6804\n",
      "1660/1660 [==============================] - 2323s 1s/step - loss: -0.5722 - dice_coefficient: 0.6804 - val_loss: -0.5422 - val_dice_coefficient: 0.6037 - lr: 5.0000e-04\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d312edf953447289e9f97b34dec753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5760 - dice_coefficient: 0.6883\n",
      "1660/1660 [==============================] - 2330s 1s/step - loss: -0.5760 - dice_coefficient: 0.6883 - val_loss: -0.5454 - val_dice_coefficient: 0.6201 - lr: 5.0000e-04\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b34051bb007411ea2137de024bfc264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5857 - dice_coefficient: 0.7012\n",
      "1660/1660 [==============================] - 2334s 1s/step - loss: -0.5857 - dice_coefficient: 0.7012 - val_loss: -0.5649 - val_dice_coefficient: 0.6372 - lr: 5.0000e-04\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48dc6d9724af40849be33c4907471fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5759 - dice_coefficient: 0.6861\n",
      "1660/1660 [==============================] - 2321s 1s/step - loss: -0.5759 - dice_coefficient: 0.6861 - val_loss: -0.5451 - val_dice_coefficient: 0.6359 - lr: 5.0000e-04\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd59b91e2542415fbb21c1c0a457cd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5741 - dice_coefficient: 0.6840\n",
      "1660/1660 [==============================] - 2327s 1s/step - loss: -0.5741 - dice_coefficient: 0.6840 - val_loss: -0.5616 - val_dice_coefficient: 0.6377 - lr: 5.0000e-04\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c68d053dcdc41f28115b183502d517b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5812 - dice_coefficient: 0.6904\n",
      "1660/1660 [==============================] - 2324s 1s/step - loss: -0.5812 - dice_coefficient: 0.6904 - val_loss: -0.5629 - val_dice_coefficient: 0.6481 - lr: 5.0000e-04\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0bdda588284919bbfaf3413fe28c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5843 - dice_coefficient: 0.6946\n",
      "1660/1660 [==============================] - 2329s 1s/step - loss: -0.5843 - dice_coefficient: 0.6946 - val_loss: -0.5534 - val_dice_coefficient: 0.6295 - lr: 5.0000e-04\n",
      "Epoch 25/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f04fd3d55d470a9728f0c1460cddd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5917 - dice_coefficient: 0.7037\n",
      "1660/1660 [==============================] - 2365s 1s/step - loss: -0.5917 - dice_coefficient: 0.7037 - val_loss: -0.5663 - val_dice_coefficient: 0.6401 - lr: 5.0000e-04\n",
      "\n",
      "Training time: 0 days, 16 hours, 12 mins, 20.264 secs.\n"
     ]
    }
   ],
   "source": [
    "##### demo_task1/train_model.py #####\n",
    "time_0 = time.time()\n",
    "train_model(model=model,\n",
    "            model_file=config[\"model_file\"],\n",
    "            training_generator=train_generator,\n",
    "            validation_generator=validation_generator,\n",
    "            steps_per_epoch=n_train_steps,\n",
    "            validation_steps=n_validation_steps,\n",
    "            initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "            learning_rate_drop=config[\"learning_rate_drop\"],\n",
    "            learning_rate_patience=config[\"patience\"],\n",
    "            early_stopping_patience=config[\"early_stop\"],\n",
    "            n_epochs=config[\"n_epochs\"],\n",
    "            logging_file = config['logging_file'])\n",
    "print('Training time:', sec2hms(time.time() - time_0))\n",
    "# data_file_opened.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T07:22:26.768645Z",
     "start_time": "2020-06-14T06:42:06.027659Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f314b3a0a684864bd018922c8755877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=25.0, style=Progr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceedb312fb2a4f3e95859b11d13badfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5942 - dice_coefficient: 0.7093\n",
      "1660/1660 [==============================] - 2390s 1s/step - loss: -0.5942 - dice_coefficient: 0.7093 - val_loss: -0.5575 - val_dice_coefficient: 0.6213 - lr: 5.0000e-04\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f4c1dceca8435bac69c0c36dd89c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n",
      "  15/1660 [..............................] - ETA: 35:11 - loss: -0.6188 - dice_coefficient: 0.7046"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-2c6337b949c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mearly_stopping_patience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"early_stop\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"n_epochs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             logging_file = config['logging_file'])\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m# data_file_opened.close()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-a48040ce2505>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, model_file, training_generator, validation_generator, steps_per_epoch, validation_steps, initial_learning_rate, learning_rate_drop, learning_rate_epochs, n_epochs, learning_rate_patience, early_stopping_patience, logging_file)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                         \u001b[0mlearning_rate_patience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate_patience\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                         \u001b[0mlogging_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                                         early_stopping_patience=early_stopping_patience))\n\u001b[0m",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = load_old_model(config[\"model_file\"])\n",
    "train_model(model=model,\n",
    "            model_file=config[\"model_file\"],\n",
    "            training_generator=train_generator,\n",
    "            validation_generator=validation_generator,\n",
    "            steps_per_epoch=n_train_steps,\n",
    "            validation_steps=n_validation_steps,\n",
    "            initial_learning_rate=0.0002 , # config[\"initial_learning_rate\"],\n",
    "            learning_rate_drop=config[\"learning_rate_drop\"],\n",
    "            learning_rate_patience=config[\"patience\"],\n",
    "            early_stopping_patience=config[\"early_stop\"],\n",
    "            n_epochs=config[\"n_epochs\"],\n",
    "            logging_file = config['logging_file'])\n",
    "# data_file_opened.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T07:22:47.775970Z",
     "start_time": "2020-06-14T07:22:47.755952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous validation split...\n",
      "Number of training steps in each epoch:  1660\n",
      "Number of validation steps in each epoch:  555\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator, n_train_steps, n_validation_steps = get_training_and_validation_generators(\n",
    "    data_file_opened,\n",
    "    batch_size= config[\"batch_size\"],\n",
    "    data_split= config[\"validation_split\"],\n",
    "    overwrite= False, #overwrite,\n",
    "    validation_keys_file=config[\"validation_file\"],\n",
    "    training_keys_file=config[\"training_file\"],\n",
    "    n_labels=config[\"n_labels\"],\n",
    "    labels=config[\"labels\"],\n",
    "    patch_shape=config[\"patch_shape\"],\n",
    "    validation_batch_size=config[\"validation_batch_size\"],\n",
    "    validation_patch_overlap=config[\"validation_patch_overlap\"],\n",
    "    training_patch_start_offset=config[\"training_patch_start_offset\"],\n",
    "    permute=config[\"permute\"],\n",
    "    augment=config[\"augment\"],\n",
    "    skip_blank=config[\"skip_blank\"],\n",
    "    #augment_flip=config[\"flip\"],\n",
    "    augment_distortion_factor=config[\"distort\"],\n",
    "    pred_specific=config['pred_specific'],\n",
    "    overlap_label=config['overlap_label_generator'],\n",
    "    #for_final_val=config['for_final_val']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:55:58.622854Z",
     "start_time": "2020-06-14T07:22:49.806948Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf9fa358d1040898458ebd32207ac41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=25.0, style=Progr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c63bbefb9844c58968ceabb04d23e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5918 - dice_coefficient: 0.6989\n",
      "1660/1660 [==============================] - 2352s 1s/step - loss: -0.5918 - dice_coefficient: 0.6989 - val_loss: -0.5719 - val_dice_coefficient: 0.6444 - lr: 5.0000e-04\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be74a74816354f3ea551d84a94a8e301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5979 - dice_coefficient: 0.7012\n",
      "1660/1660 [==============================] - 2356s 1s/step - loss: -0.5979 - dice_coefficient: 0.7012 - val_loss: -0.5651 - val_dice_coefficient: 0.6306 - lr: 5.0000e-04\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ea0a4e564446d4ac3a37d6dec879cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5984 - dice_coefficient: 0.7063\n",
      "1660/1660 [==============================] - 2401s 1s/step - loss: -0.5984 - dice_coefficient: 0.7063 - val_loss: -0.5811 - val_dice_coefficient: 0.6601 - lr: 5.0000e-04\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613415e348d341c38943ec9dff9eadab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5985 - dice_coefficient: 0.7160\n",
      "1660/1660 [==============================] - 2349s 1s/step - loss: -0.5985 - dice_coefficient: 0.7160 - val_loss: -0.5787 - val_dice_coefficient: 0.6625 - lr: 5.0000e-04\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee806db4227d4c9290cf201420ba2eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.6010 - dice_coefficient: 0.7085\n",
      "1660/1660 [==============================] - 2333s 1s/step - loss: -0.6010 - dice_coefficient: 0.7085 - val_loss: -0.5760 - val_dice_coefficient: 0.6518 - lr: 5.0000e-04\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4333f56ce34c46a4f2dc60b4d9f0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.5976 - dice_coefficient: 0.7093\n",
      "1660/1660 [==============================] - 2373s 1s/step - loss: -0.5976 - dice_coefficient: 0.7093 - val_loss: -0.5712 - val_dice_coefficient: 0.6601 - lr: 5.0000e-04\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7d5320b33b4e93bd1d51bd23be6dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.6432 - dice_coefficient: 0.6984\n",
      "1660/1660 [==============================] - 2365s 1s/step - loss: -0.6432 - dice_coefficient: 0.6984 - val_loss: -0.6307 - val_dice_coefficient: 0.6444 - lr: 5.0000e-04\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71068d0c838948a8ac3b11797dad4b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.6789 - dice_coefficient: 0.6920\n",
      "1660/1660 [==============================] - 2366s 1s/step - loss: -0.6789 - dice_coefficient: 0.6920 - val_loss: -0.6546 - val_dice_coefficient: 0.6398 - lr: 5.0000e-04\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860b6b01d71742b5aefd682a655d1f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.6682 - dice_coefficient: 0.6941\n",
      "1660/1660 [==============================] - 2358s 1s/step - loss: -0.6682 - dice_coefficient: 0.6941 - val_loss: -0.6104 - val_dice_coefficient: 0.6229 - lr: 5.0000e-04\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d368dc91e44c7099358fe35377aad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.6556 - dice_coefficient: 0.6844\n",
      "1660/1660 [==============================] - 2349s 1s/step - loss: -0.6556 - dice_coefficient: 0.6844 - val_loss: -0.6338 - val_dice_coefficient: 0.6340 - lr: 5.0000e-04\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f09bc05293439ba513ead43c875d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.6646 - dice_coefficient: 0.6867\n",
      "1660/1660 [==============================] - 2355s 1s/step - loss: -0.6646 - dice_coefficient: 0.6867 - val_loss: -0.6504 - val_dice_coefficient: 0.6325 - lr: 5.0000e-04\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafba554c9424fb5b5a056386ee4fa6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.6647 - dice_coefficient: 0.6820\n",
      "1660/1660 [==============================] - 2340s 1s/step - loss: -0.6647 - dice_coefficient: 0.6820 - val_loss: -0.6448 - val_dice_coefficient: 0.6225 - lr: 5.0000e-04\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511073b5ea87419b87243829d79cd834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.6678 - dice_coefficient: 0.6855\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "1660/1660 [==============================] - 2403s 1s/step - loss: -0.6678 - dice_coefficient: 0.6855 - val_loss: -0.6212 - val_dice_coefficient: 0.6255 - lr: 5.0000e-04\n",
      "Epoch 14/25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86d4488dca848d4a80f23f58ad51717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1660.0), HTML(value='')), layout=Layout(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25\n",
      "  47/1660 [..............................] - ETA: 34:03 - loss: -0.6945 - dice_coefficient: 0.6659"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-1d443c17c9ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mearly_stopping_patience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"early_stop\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"n_epochs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             logging_file = config['logging_file'])\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-a48040ce2505>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, model_file, training_generator, validation_generator, steps_per_epoch, validation_steps, initial_learning_rate, learning_rate_drop, learning_rate_epochs, n_epochs, learning_rate_patience, early_stopping_patience, logging_file)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                         \u001b[0mlearning_rate_patience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate_patience\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                         \u001b[0mlogging_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                                         early_stopping_patience=early_stopping_patience))\n\u001b[0m",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \"\"\"\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    517\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \"\"\"\n\u001b[0;32m    960\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = load_old_model(config[\"model_file\"])\n",
    "train_model(model=model,\n",
    "            model_file=config[\"model_file\"],\n",
    "            training_generator=train_generator,\n",
    "            validation_generator=validation_generator,\n",
    "            steps_per_epoch=n_train_steps,\n",
    "            validation_steps=n_validation_steps,\n",
    "            initial_learning_rate=0.0002 ,#config[\"initial_learning_rate\"],\n",
    "            learning_rate_drop=config[\"learning_rate_drop\"],\n",
    "            learning_rate_patience=config[\"patience\"],\n",
    "            early_stopping_patience=config[\"early_stop\"],\n",
    "            n_epochs=config[\"n_epochs\"],\n",
    "            logging_file = config['logging_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T16:41:01.691247Z",
     "start_time": "2020-06-14T16:41:01.674232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous validation split...\n",
      "Number of training steps in each epoch:  1660\n",
      "Number of validation steps in each epoch:  555\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator, n_train_steps, n_validation_steps = get_training_and_validation_generators(\n",
    "    data_file_opened,\n",
    "    batch_size= config[\"batch_size\"],\n",
    "    data_split= config[\"validation_split\"],\n",
    "    overwrite= False, #overwrite,\n",
    "    validation_keys_file=config[\"validation_file\"],\n",
    "    training_keys_file=config[\"training_file\"],\n",
    "    n_labels=config[\"n_labels\"],\n",
    "    labels=config[\"labels\"],\n",
    "    patch_shape=config[\"patch_shape\"],\n",
    "    validation_batch_size=config[\"validation_batch_size\"],\n",
    "    validation_patch_overlap=config[\"validation_patch_overlap\"],\n",
    "    training_patch_start_offset=config[\"training_patch_start_offset\"],\n",
    "    permute=config[\"permute\"],\n",
    "    augment=config[\"augment\"],\n",
    "    skip_blank=config[\"skip_blank\"],\n",
    "    #augment_flip=config[\"flip\"],\n",
    "    augment_distortion_factor=config[\"distort\"],\n",
    "    pred_specific=config['pred_specific'],\n",
    "    overlap_label=config['overlap_label_generator'],\n",
    "    #for_final_val=config['for_final_val']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T16:41:05.021138Z",
     "start_time": "2020-06-14T16:41:02.641605Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model\n"
     ]
    }
   ],
   "source": [
    "model = load_old_model(config[\"model_file\"])\n",
    "model.compile(optimizer=Adam(lr=0.0002), loss=weighted_dice_coefficient_loss, metrics=dice_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T16:41:05.037153Z",
     "start_time": "2020-06-14T16:41:05.022139Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "def get_callbacks(model_file, initial_learning_rate=0.0001, learning_rate_drop=0.5, learning_rate_epochs=None,\n",
    "                  learning_rate_patience=50, logging_file=\"training.log\", verbosity=1,\n",
    "                  early_stopping_patience=None):\n",
    "    callbacks = list()\n",
    "    callbacks.append(ModelCheckpoint(model_file, save_best_only=True))\n",
    "    callbacks.append(CSVLogger(logging_file, append=True))\n",
    "    if learning_rate_epochs:\n",
    "        callbacks.append(LearningRateScheduler(partial(step_decay, initial_lrate=initial_learning_rate,\n",
    "                                                       drop=learning_rate_drop, epochs_drop=learning_rate_epochs)))\n",
    "    else:\n",
    "        callbacks.append(ReduceLROnPlateau(factor=learning_rate_drop, patience=learning_rate_patience,\n",
    "                                           verbose=verbosity))\n",
    "    if early_stopping_patience:\n",
    "        callbacks.append(EarlyStopping(verbose=verbosity, patience=early_stopping_patience))\n",
    "    callbacks.append(tensorboard_callback)\n",
    "    return callbacks\n",
    "\n",
    "def train_model(model, model_file, training_generator, validation_generator, steps_per_epoch, validation_steps,\n",
    "                initial_learning_rate=0.001, learning_rate_drop=0.5, learning_rate_epochs=None, n_epochs=500,\n",
    "                learning_rate_patience=20, early_stopping_patience=None, logging_file = 'training.log'):\n",
    "    model.fit(x=training_generator,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=n_epochs,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=validation_steps,\n",
    "                callbacks=get_callbacks(model_file,\n",
    "                                        initial_learning_rate=initial_learning_rate,\n",
    "                                        learning_rate_drop=learning_rate_drop,\n",
    "                                        learning_rate_epochs=learning_rate_epochs,\n",
    "                                        learning_rate_patience=learning_rate_patience,\n",
    "                                        logging_file = logging_file,\n",
    "                                        early_stopping_patience=early_stopping_patience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T16:41:10.125377Z",
     "start_time": "2020-06-14T16:41:10.121373Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T09:03:20.195592Z",
     "start_time": "2020-06-14T16:41:11.106269Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1660/1660 [==============================] - 2330s 1s/step - loss: -0.7075 - dice_coefficient: 0.7254 - val_loss: -0.6510 - val_dice_coefficient: 0.6465 - lr: 2.0000e-04\n",
      "Epoch 2/25\n",
      "1660/1660 [==============================] - 2345s 1s/step - loss: -0.7060 - dice_coefficient: 0.7155 - val_loss: -0.6656 - val_dice_coefficient: 0.6484 - lr: 2.0000e-04\n",
      "Epoch 3/25\n",
      "1660/1660 [==============================] - 2333s 1s/step - loss: -0.6939 - dice_coefficient: 0.7093 - val_loss: -0.6713 - val_dice_coefficient: 0.6562 - lr: 2.0000e-04\n",
      "Epoch 4/25\n",
      "1660/1660 [==============================] - 2343s 1s/step - loss: -0.7222 - dice_coefficient: 0.7256 - val_loss: -0.6604 - val_dice_coefficient: 0.6535 - lr: 2.0000e-04\n",
      "Epoch 5/25\n",
      "1660/1660 [==============================] - 2343s 1s/step - loss: -0.7117 - dice_coefficient: 0.7211 - val_loss: -0.6708 - val_dice_coefficient: 0.6655 - lr: 2.0000e-04\n",
      "Epoch 6/25\n",
      "1660/1660 [==============================] - 2340s 1s/step - loss: -0.7150 - dice_coefficient: 0.7233 - val_loss: -0.6678 - val_dice_coefficient: 0.6531 - lr: 2.0000e-04\n",
      "Epoch 7/25\n",
      "1660/1660 [==============================] - 2348s 1s/step - loss: -0.7159 - dice_coefficient: 0.7241 - val_loss: -0.6703 - val_dice_coefficient: 0.6525 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.7124 - dice_coefficient: 0.7247\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
      "1660/1660 [==============================] - 2336s 1s/step - loss: -0.7124 - dice_coefficient: 0.7247 - val_loss: -0.6653 - val_dice_coefficient: 0.6635 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "1660/1660 [==============================] - 2347s 1s/step - loss: -0.7229 - dice_coefficient: 0.7339 - val_loss: -0.6544 - val_dice_coefficient: 0.6654 - lr: 1.0000e-04\n",
      "Epoch 10/25\n",
      "1660/1660 [==============================] - 2341s 1s/step - loss: -0.7293 - dice_coefficient: 0.7398 - val_loss: -0.6633 - val_dice_coefficient: 0.6445 - lr: 1.0000e-04\n",
      "Epoch 11/25\n",
      "1660/1660 [==============================] - 2354s 1s/step - loss: -0.7317 - dice_coefficient: 0.7370 - val_loss: -0.6683 - val_dice_coefficient: 0.6621 - lr: 1.0000e-04\n",
      "Epoch 12/25\n",
      "1660/1660 [==============================] - 2349s 1s/step - loss: -0.7267 - dice_coefficient: 0.7367 - val_loss: -0.6727 - val_dice_coefficient: 0.6480 - lr: 1.0000e-04\n",
      "Epoch 13/25\n",
      "1660/1660 [==============================] - 2338s 1s/step - loss: -0.7301 - dice_coefficient: 0.7271 - val_loss: -0.6723 - val_dice_coefficient: 0.6593 - lr: 1.0000e-04\n",
      "Epoch 14/25\n",
      "1660/1660 [==============================] - 2351s 1s/step - loss: -0.7292 - dice_coefficient: 0.7365 - val_loss: -0.6748 - val_dice_coefficient: 0.6648 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "1660/1660 [==============================] - 2371s 1s/step - loss: -0.7351 - dice_coefficient: 0.7402 - val_loss: -0.6756 - val_dice_coefficient: 0.6663 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1660/1660 [==============================] - 2357s 1s/step - loss: -0.7341 - dice_coefficient: 0.7403 - val_loss: -0.6815 - val_dice_coefficient: 0.6652 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1660/1660 [==============================] - 2350s 1s/step - loss: -0.7299 - dice_coefficient: 0.7404 - val_loss: -0.6798 - val_dice_coefficient: 0.6758 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1660/1660 [==============================] - 2375s 1s/step - loss: -0.7421 - dice_coefficient: 0.7375 - val_loss: -0.6657 - val_dice_coefficient: 0.6367 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1660/1660 [==============================] - 2368s 1s/step - loss: -0.7324 - dice_coefficient: 0.7372 - val_loss: -0.6883 - val_dice_coefficient: 0.6654 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1660/1660 [==============================] - 2386s 1s/step - loss: -0.7342 - dice_coefficient: 0.7432 - val_loss: -0.6881 - val_dice_coefficient: 0.6719 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1660/1660 [==============================] - 2384s 1s/step - loss: -0.7330 - dice_coefficient: 0.7319 - val_loss: -0.6803 - val_dice_coefficient: 0.6552 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1660/1660 [==============================] - 2369s 1s/step - loss: -0.7397 - dice_coefficient: 0.7386 - val_loss: -0.6791 - val_dice_coefficient: 0.6587 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1660/1660 [==============================] - 2370s 1s/step - loss: -0.7349 - dice_coefficient: 0.7335 - val_loss: -0.6898 - val_dice_coefficient: 0.6654 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1660/1660 [==============================] - 2362s 1s/step - loss: -0.7389 - dice_coefficient: 0.7360 - val_loss: -0.6795 - val_dice_coefficient: 0.6570 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1660/1660 [==============================] - 2384s 1s/step - loss: -0.7386 - dice_coefficient: 0.7485 - val_loss: -0.6735 - val_dice_coefficient: 0.6679 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "train_model(model=model,\n",
    "            model_file=config[\"model_file\"],\n",
    "            training_generator=train_generator,\n",
    "            validation_generator=validation_generator,\n",
    "            steps_per_epoch=n_train_steps,\n",
    "            validation_steps=n_validation_steps,\n",
    "            initial_learning_rate= 0.0002, # config[\"initial_learning_rate\"],\n",
    "            learning_rate_drop=config[\"learning_rate_drop\"],\n",
    "            learning_rate_patience=config[\"patience\"],\n",
    "            early_stopping_patience=config[\"early_stop\"],\n",
    "            n_epochs=config[\"n_epochs\"],\n",
    "            logging_file = config['logging_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:56:10.864305Z",
     "start_time": "2020-06-15T14:56:09.611665Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous validation split...\n",
      "Number of training steps in each epoch:  1660\n",
      "Number of validation steps in each epoch:  555\n",
      "Loading pre-trained model\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator, n_train_steps, n_validation_steps = get_training_and_validation_generators(\n",
    "    data_file_opened,\n",
    "    batch_size= config[\"batch_size\"],\n",
    "    data_split= config[\"validation_split\"],\n",
    "    overwrite= False, #overwrite,\n",
    "    validation_keys_file=config[\"validation_file\"],\n",
    "    training_keys_file=config[\"training_file\"],\n",
    "    n_labels=config[\"n_labels\"],\n",
    "    labels=config[\"labels\"],\n",
    "    patch_shape=config[\"patch_shape\"],\n",
    "    validation_batch_size=config[\"validation_batch_size\"],\n",
    "    validation_patch_overlap=config[\"validation_patch_overlap\"],\n",
    "    training_patch_start_offset=config[\"training_patch_start_offset\"],\n",
    "    permute=config[\"permute\"],\n",
    "    augment=config[\"augment\"],\n",
    "    skip_blank=config[\"skip_blank\"],\n",
    "    #augment_flip=config[\"flip\"],\n",
    "    augment_distortion_factor=config[\"distort\"],\n",
    "    pred_specific=config['pred_specific'],\n",
    "    overlap_label=config['overlap_label_generator'],\n",
    "    #for_final_val=config['for_final_val']\n",
    "    )\n",
    "\n",
    "model = load_old_model(config[\"model_file\"])\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss=weighted_dice_coefficient_loss, metrics=dice_coefficient)\n",
    "\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "def get_callbacks(model_file, initial_learning_rate=0.0001, learning_rate_drop=0.5, learning_rate_epochs=None,\n",
    "                  learning_rate_patience=50, logging_file=\"training.log\", verbosity=1,\n",
    "                  early_stopping_patience=None):\n",
    "    callbacks = list()\n",
    "    callbacks.append(ModelCheckpoint(model_file, save_best_only=True))\n",
    "    callbacks.append(CSVLogger(logging_file, append=True))\n",
    "    if learning_rate_epochs:\n",
    "        callbacks.append(LearningRateScheduler(partial(step_decay, initial_lrate=initial_learning_rate,\n",
    "                                                       drop=learning_rate_drop, epochs_drop=learning_rate_epochs)))\n",
    "    else:\n",
    "        callbacks.append(ReduceLROnPlateau(factor=learning_rate_drop, patience=learning_rate_patience,\n",
    "                                           verbose=verbosity))\n",
    "    if early_stopping_patience:\n",
    "        callbacks.append(EarlyStopping(verbose=verbosity, patience=early_stopping_patience))\n",
    "    callbacks.append(tensorboard_callback)\n",
    "    return callbacks\n",
    "\n",
    "def train_model(model, model_file, training_generator, validation_generator, steps_per_epoch, validation_steps,\n",
    "                initial_learning_rate=0.001, learning_rate_drop=0.5, learning_rate_epochs=None, n_epochs=500,\n",
    "                learning_rate_patience=20, early_stopping_patience=None, logging_file = 'training.log'):\n",
    "    model.fit(x=training_generator,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=n_epochs,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=validation_steps,\n",
    "                callbacks=get_callbacks(model_file,\n",
    "                                        initial_learning_rate=initial_learning_rate,\n",
    "                                        learning_rate_drop=learning_rate_drop,\n",
    "                                        learning_rate_epochs=learning_rate_epochs,\n",
    "                                        learning_rate_patience=learning_rate_patience,\n",
    "                                        logging_file = logging_file,\n",
    "                                        early_stopping_patience=early_stopping_patience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:56:12.426746Z",
     "start_time": "2020-06-15T14:56:12.418739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T00:44:54.395923Z",
     "start_time": "2020-06-15T14:56:12.899670Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1660/1660 [==============================] - 2339s 1s/step - loss: -0.7359 - dice_coefficient: 0.7430 - val_loss: -0.6772 - val_dice_coefficient: 0.6679 - lr: 1.0000e-04\n",
      "Epoch 2/25\n",
      "1660/1660 [==============================] - 2346s 1s/step - loss: -0.7334 - dice_coefficient: 0.7397 - val_loss: -0.6894 - val_dice_coefficient: 0.6683 - lr: 1.0000e-04\n",
      "Epoch 3/25\n",
      "1660/1660 [==============================] - 2351s 1s/step - loss: -0.7409 - dice_coefficient: 0.7381 - val_loss: -0.6796 - val_dice_coefficient: 0.6558 - lr: 1.0000e-04\n",
      "Epoch 4/25\n",
      "1660/1660 [==============================] - 2330s 1s/step - loss: -0.7413 - dice_coefficient: 0.7331 - val_loss: -0.6914 - val_dice_coefficient: 0.6700 - lr: 1.0000e-04\n",
      "Epoch 5/25\n",
      "1660/1660 [==============================] - 2332s 1s/step - loss: -0.7304 - dice_coefficient: 0.7367 - val_loss: -0.6847 - val_dice_coefficient: 0.6624 - lr: 1.0000e-04\n",
      "Epoch 6/25\n",
      "1660/1660 [==============================] - 2332s 1s/step - loss: -0.7325 - dice_coefficient: 0.7339 - val_loss: -0.6812 - val_dice_coefficient: 0.6559 - lr: 1.0000e-04\n",
      "Epoch 7/25\n",
      "1660/1660 [==============================] - 2338s 1s/step - loss: -0.7390 - dice_coefficient: 0.7435 - val_loss: -0.6816 - val_dice_coefficient: 0.6701 - lr: 1.0000e-04\n",
      "Epoch 8/25\n",
      "1660/1660 [==============================] - 2324s 1s/step - loss: -0.7405 - dice_coefficient: 0.7378 - val_loss: -0.6873 - val_dice_coefficient: 0.6646 - lr: 1.0000e-04\n",
      "Epoch 9/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.7362 - dice_coefficient: 0.7417\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "1660/1660 [==============================] - 2340s 1s/step - loss: -0.7362 - dice_coefficient: 0.7417 - val_loss: -0.6872 - val_dice_coefficient: 0.6653 - lr: 1.0000e-04\n",
      "Epoch 10/25\n",
      "1660/1660 [==============================] - 2335s 1s/step - loss: -0.7457 - dice_coefficient: 0.7427 - val_loss: -0.6821 - val_dice_coefficient: 0.6743 - lr: 5.0000e-05\n",
      "Epoch 11/25\n",
      "1660/1660 [==============================] - 2327s 1s/step - loss: -0.7430 - dice_coefficient: 0.7420 - val_loss: -0.6838 - val_dice_coefficient: 0.6616 - lr: 5.0000e-05\n",
      "Epoch 12/25\n",
      "1660/1660 [==============================] - 2329s 1s/step - loss: -0.7460 - dice_coefficient: 0.7460 - val_loss: -0.6861 - val_dice_coefficient: 0.6679 - lr: 5.0000e-05\n",
      "Epoch 13/25\n",
      "1660/1660 [==============================] - 2336s 1s/step - loss: -0.7459 - dice_coefficient: 0.7441 - val_loss: -0.6847 - val_dice_coefficient: 0.6722 - lr: 5.0000e-05\n",
      "Epoch 14/25\n",
      "1660/1660 [==============================] - ETA: 0s - loss: -0.7480 - dice_coefficient: 0.7466\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "1660/1660 [==============================] - 2334s 1s/step - loss: -0.7480 - dice_coefficient: 0.7466 - val_loss: -0.6830 - val_dice_coefficient: 0.6715 - lr: 5.0000e-05\n",
      "Epoch 15/25\n",
      "1660/1660 [==============================] - 2336s 1s/step - loss: -0.7433 - dice_coefficient: 0.7505 - val_loss: -0.6886 - val_dice_coefficient: 0.6751 - lr: 2.5000e-05\n",
      "Epoch 16/25\n",
      " 200/1660 [==>...........................] - ETA: 31:51 - loss: -0.7459 - dice_coefficient: 0.7540"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7a4b9fe596fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mearly_stopping_patience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"early_stop\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"n_epochs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             logging_file = config['logging_file'])\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-9f7efe53008a>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, model_file, training_generator, validation_generator, steps_per_epoch, validation_steps, initial_learning_rate, learning_rate_drop, learning_rate_epochs, n_epochs, learning_rate_patience, early_stopping_patience, logging_file)\u001b[0m\n\u001b[0;32m     61\u001b[0m                                         \u001b[0mlearning_rate_patience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate_patience\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                                         \u001b[0mlogging_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                                         early_stopping_patience=early_stopping_patience))\n\u001b[0m",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \"\"\"\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    517\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \"\"\"\n\u001b[0;32m    960\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\iamedic\\myenv_tf21\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model=model,\n",
    "            model_file=config[\"model_file\"],\n",
    "            training_generator=train_generator,\n",
    "            validation_generator=validation_generator,\n",
    "            steps_per_epoch=n_train_steps,\n",
    "            validation_steps=n_validation_steps,\n",
    "            initial_learning_rate= 0.0001, # config[\"initial_learning_rate\"],\n",
    "            learning_rate_drop=config[\"learning_rate_drop\"],\n",
    "            learning_rate_patience=config[\"patience\"],\n",
    "            early_stopping_patience=config[\"early_stop\"],\n",
    "            n_epochs=config[\"n_epochs\"],\n",
    "            logging_file = config['logging_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T00:46:43.517286Z",
     "start_time": "2020-06-16T00:46:43.282081Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(filepath='C:/IAMEDIC/Jaeho_code/seg_model_1.31.h5',\n",
    "           overwrite=True, include_optimizer=True, save_format=None,\n",
    "           signatures=None, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:53:29.760978Z",
     "start_time": "2020-06-16T01:53:29.753972Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:53:30.337005Z",
     "start_time": "2020-06-16T01:53:30.313983Z"
    }
   },
   "outputs": [],
   "source": [
    "##### unet3d/prediction.py #####\n",
    "\n",
    "def run_validation_case(data_index, output_dir, model, data_file, training_modalities,\n",
    "                        threshold=0.5, labels=None, overlap=16, \n",
    "                        permute=False, center_patch=True, overlap_label=True, \n",
    "                        final_val=False):\n",
    "#     pdb.set_trace()\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    affine = np.load('./affine.npy')\n",
    "    test_data = np.array([modality_img[data_index,0] \n",
    "                      for modality_img in [data_file.root.t1,\n",
    "                                           data_file.root.t1ce,\n",
    "                                           data_file.root.flair,\n",
    "                                           data_file.root.t2]])[np.newaxis]\n",
    "    for i in range(test_data.shape[1]):\n",
    "        if i == 0:\n",
    "            brain_mask = np.copy(test_data[0,i])\n",
    "            brain_mask[np.nonzero(brain_mask)] = True\n",
    "        else:\n",
    "            temp_mask = np.copy(test_data[0,i])\n",
    "            temp_mask[np.nonzero(temp_mask)] = True\n",
    "            brain_mask = np.logical_or(brain_mask,temp_mask)\n",
    "    \n",
    "    \n",
    "    for i, modality in enumerate(training_modalities):\n",
    "        image = nib.Nifti1Image(test_data[0, i], affine)\n",
    "        image.to_filename(os.path.join(output_dir, \"data_{0}.nii.gz\".format(modality)))\n",
    "    \n",
    "    if not final_val:\n",
    "        test_truth = nib.Nifti1Image(data_file.root.truth[data_index][0], affine)\n",
    "        test_truth.to_filename(os.path.join(output_dir, \"truth.nii.gz\"))\n",
    "    \n",
    "    brain_width = data_file.root.brain_width[data_index]\n",
    "\n",
    "    patch_shape = tuple([int(dim) for dim in model.input.shape[-3:]])\n",
    "    if patch_shape == test_data.shape[-3:]:\n",
    "        prediction = predict(model, test_data, permute=permute)\n",
    "    else:\n",
    "        prediction = patch_wise_prediction(model=model, data=test_data, brain_width=brain_width,\n",
    "                                           overlap=overlap, permute=permute, center_patch=center_patch)[np.newaxis]\n",
    "#     pdb.set_trace()\n",
    "    prediction_image = prediction_to_image(prediction, affine, brain_mask,\n",
    "                                           threshold=threshold, labels=labels,output_dir=output_dir,overlap_label=overlap_label)\n",
    "    if isinstance(prediction_image, list):\n",
    "        for i, image in enumerate(prediction_image):\n",
    "            image.to_filename(os.path.join(output_dir, \"prediction_{0}.nii.gz\".format(i + 1)))\n",
    "    else:\n",
    "        prediction_image.to_filename(os.path.join(output_dir, data_file.root.subject_ids[data_index].decode()+'.nii.gz'))\n",
    "\n",
    "\n",
    "def run_validation_cases(validation_keys_file, model_file, training_modalities, labels, hdf5_file,\n",
    "                         output_dir=\".\", threshold=0.5, overlap=16, \n",
    "                         permute=False,center_patch=True, overlap_label=True, final_val = False):\n",
    "    validation_indices = pickle_load(validation_keys_file)\n",
    "    model = load_old_model(model_file)\n",
    "    data_file = tables.open_file(hdf5_file, \"r\")\n",
    "    \n",
    "    for index in tqdm(validation_indices):\n",
    "        if 'subject_ids' in data_file.root:\n",
    "            case_directory = os.path.join(output_dir, data_file.root.subject_ids[index].decode('utf-8'))\n",
    "        else:\n",
    "            case_directory = os.path.join(output_dir, \"validation_case_{}\".format(index))\n",
    "        run_validation_case(data_index=index, output_dir=case_directory, model=model, data_file=data_file,\n",
    "                            training_modalities=training_modalities, labels=labels,\n",
    "                            threshold=threshold, overlap=overlap, permute=permute, center_patch=center_patch,\n",
    "                            overlap_label=overlap_label,\n",
    "                            final_val=final_val)\n",
    "    data_file.close()\n",
    "#     pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-16T02:31:49.642Z"
    }
   },
   "outputs": [],
   "source": [
    "##### demo_task1/data_for_val.py\n",
    "# uc: unchanged\n",
    "import os\n",
    "import pdb\n",
    "import numpy as np\n",
    "import tables\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "#from dev_tools.my_tools import print_red\n",
    "#from unet3d.normalize import normalize_data_storage_val\n",
    "#from unet3d.data import cal_outline\n",
    "\n",
    "def create_data_file(out_file, n_samples, image_shape, modality_names):\n",
    "#     pdb.set_trace()\n",
    "    hdf5_file = tables.open_file(out_file, mode='w')\n",
    "    filters = tables.Filters(complevel=5, complib='blosc')\n",
    "    modality_shape = tuple([0, 1] + list(image_shape))\n",
    "    brain_width_shape = (0,2,3)\n",
    "    \n",
    "    \n",
    "    modality_storage_list = [hdf5_file.create_earray(hdf5_file.root, modality_name, tables.Float32Atom(), shape=modality_shape,\n",
    "                             filters=filters, expectedrows=n_samples) for modality_name in modality_names]\n",
    "    \n",
    "    brain_width_storage = hdf5_file.create_earray(hdf5_file.root, 'brain_width', tables.UInt8Atom(), shape=brain_width_shape,\n",
    "                                            filters=filters, expectedrows=n_samples)\n",
    "    \n",
    "    return hdf5_file, modality_storage_list, brain_width_storage\n",
    "\n",
    "\n",
    "\n",
    "def write_image_data_to_file(image_files, data_storage,brain_width_storage, \n",
    "                             image_shape, modality_names, trivial_check = True):\n",
    "    '''\n",
    "    trivial_check: to see if all images share the same affine info and pad_width, the incompliance file names \n",
    "                   would be printed in red lines.\n",
    "                   Also to check the order of modalities when added to the .h5\n",
    "    '''\n",
    "#     pdb.set_trace()\n",
    "    affine_0 = np.load('affine.npy')\n",
    "    \n",
    "#     temp = 0\n",
    "    print('write_image_data_to_file...')\n",
    "    for set_of_files in tqdm(image_files):\n",
    "        if trivial_check:\n",
    "            if not [os.path.basename(img_file).split('.')[0] for img_file in set_of_files] == modality_names:\n",
    "                print('wrong order of modalities')\n",
    "                print_red(image_nii_path)\n",
    "        subject_data = []\n",
    "        brain_widths = []\n",
    "        for i,image_nii_path in enumerate(set_of_files):\n",
    "            img = nib.load(image_nii_path)\n",
    "            affine = img.affine\n",
    "            if trivial_check:\n",
    "                if np.sum(affine_0 - affine):\n",
    "                    print('affine incompliance:')\n",
    "                    print_red(image_nii_path)\n",
    "            img_npy = img.get_data()\n",
    "            subject_data.append(img_npy)\n",
    "            \n",
    "            brain_widths.append(cal_outline(img_npy))\n",
    "                \n",
    "        start_edge = np.min(brain_widths,axis=0)[0]\n",
    "        end_edge = np.max(brain_widths,axis=0)[1]\n",
    "        brain_width = np.vstack((start_edge,end_edge))\n",
    "        \n",
    "        if add_data_to_storage(data_storage, brain_width_storage, \n",
    "                               subject_data, brain_width, modality_names = modality_names):\n",
    "            print_red('modality_storage.name != modality_name')\n",
    "            print_red(set_of_files)\n",
    "    print('write_image_data_to_file...FINISHED')\n",
    "    return data_storage\n",
    "\n",
    "\n",
    "def add_data_to_storage(data_storage, brain_width_storage, \n",
    "                        subject_data, brain_width, modality_names):\n",
    "#     pdb.set_trace()\n",
    "    for i in range(len(modality_names)):\n",
    "        if data_storage[i].name != modality_names[i]:\n",
    "            print_red('modality_storage.name != modality_name')\n",
    "            return \n",
    "        data_storage[i].append(np.asarray(subject_data[i])[np.newaxis][np.newaxis])\n",
    "    \n",
    "    brain_width_storage.append(np.asarray(brain_width, dtype=np.uint8)[np.newaxis])\n",
    "    return 0\n",
    "\n",
    "def write_data_to_file(training_data_files, out_file, image_shape, modality_names, subject_ids=None,\n",
    "                       normalize=True, mean_std_file='../data/mean_std.pkl'):\n",
    "\n",
    "#     pdb.set_trace()\n",
    "    n_samples = len(training_data_files)\n",
    "\n",
    "    hdf5_file, data_storage, brain_width_storage = create_data_file(out_file,\n",
    "                                                                      n_samples=n_samples,\n",
    "                                                                      image_shape=image_shape,\n",
    "                                                                      modality_names = modality_names)\n",
    "\n",
    "    write_image_data_to_file(training_data_files, \n",
    "                                data_storage, brain_width_storage, \n",
    "                                image_shape, modality_names = modality_names)\n",
    "    if subject_ids:\n",
    "        hdf5_file.create_array(hdf5_file.root, 'subject_ids', obj=subject_ids)\n",
    "    if normalize:\n",
    "        normalize_data_storage_val(data_storage, save_file = mean_std_file)\n",
    "    hdf5_file.close()\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-16T02:31:50.257Z"
    }
   },
   "outputs": [],
   "source": [
    "##### demo_task1/run_validation.py #####\n",
    "import os\n",
    "#from train_model import config\n",
    "import pdb\n",
    "import glob\n",
    "#from data_for_val import write_data_to_file\n",
    "# from unet3d.prediction import run_validation_cases\n",
    "import pickle\n",
    "#from dev_tools.my_tools import my_mkdir, my_makedirs\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "def fetch_val_data_files(return_subject_ids=True):\n",
    "#     pdb.set_trace()\n",
    "    val_data_files = list()\n",
    "    subject_ids = list()\n",
    "    for subject_dir in glob.glob(os.path.join(\"C:/IAMEDIC/Jaeho_code/data\", \"preprocessed_val_data\", \"*\", \"*\")):\n",
    "        subject_ids.append(os.path.basename(subject_dir))\n",
    "        subject_files = list()\n",
    "        for modality in config['all_modalities']:\n",
    "            subject_files.append(os.path.join(subject_dir, modality + \".nii.gz\"))\n",
    "        val_data_files.append(tuple(subject_files))\n",
    "    if return_subject_ids:\n",
    "        return val_data_files, subject_ids\n",
    "    else:\n",
    "        return val_data_files\n",
    "\n",
    "\n",
    "def gen_val_h5():\n",
    "    if os.path.exists(config['val_data_file']):\n",
    "        print(config['val_data_file'],'exists already!')\n",
    "        return\n",
    "\n",
    "    val_files, subject_ids = fetch_val_data_files()\n",
    "\n",
    "    write_data_to_file(val_files, \n",
    "                        config['val_data_file'], \n",
    "                        image_shape=config[\"image_shape\"], \n",
    "                        modality_names = config['all_modalities'],\n",
    "                        subject_ids=subject_ids,\n",
    "                       mean_std_file = config['mean_std_file'])\n",
    "    return\n",
    "    \n",
    "def mv_results(source_dir,target_dir):\n",
    "#     print('moving for upload...')\n",
    "    my_makedirs(target_dir)\n",
    "    for sub_id in tqdm(os.listdir(source_dir)):\n",
    "        source_name = os.path.join(source_dir,sub_id,sub_id+'.nii.gz')\n",
    "        target_name = os.path.join(target_dir,sub_id+'.nii.gz')\n",
    "        if not os.path.exists(target_name):\n",
    "            shutil.move(source_name,target_name)\n",
    "    \n",
    "def main_run():\n",
    "    config['num_val_subjects'] = len(os.listdir('C:/IAMEDIC/Jaeho_code/data/preprocessed_val_data/val'))\n",
    "    \n",
    "    gen_val_h5()\n",
    "    \n",
    "    if not os.path.exists(config['val_index_list']):\n",
    "        with open(config['val_index_list'],'wb') as f:\n",
    "            pickle.dump(list(range(config['num_val_subjects'])),f)\n",
    "    print('Validation dataset prediction starts...')        \n",
    "    run_validation_cases(validation_keys_file=config['val_index_list'],\n",
    "                         model_file=config[\"model_file\"],\n",
    "                         training_modalities=config[\"training_modalities\"],\n",
    "                         labels=config[\"labels\"],\n",
    "                         hdf5_file=config[\"val_data_file\"],\n",
    "                         output_dir=config['val_predict_dir'],\n",
    "                         center_patch=config['center_patch'],\n",
    "                         overlap_label=config['overlap_label_predict'],\n",
    "                         final_val = True)\n",
    "    mv_results(config['val_predict_dir'],config['val_to_upload'])\n",
    "    print('Validation dataset prediction finished.')\n",
    "    return\n",
    "\n",
    "# def predict_training_dataset():\n",
    "#     if not os.path.exists(config['training_index_list']):\n",
    "#         with open(config['training_index_list'],'wb') as f:\n",
    "#             pickle.dump(list(range(config['num_training_subjects'])),f)\n",
    "#     print('Training dataset prediction starts...')        \n",
    "#     run_validation_cases(validation_keys_file=config['training_index_list'],\n",
    "#                          model_file=config[\"model_file\"],\n",
    "#                          training_modalities=config[\"training_modalities\"],\n",
    "#                          labels=config[\"labels\"],\n",
    "#                          hdf5_file=config[\"data_file\"],\n",
    "#                          output_dir=config['training_predict_dir'],\n",
    "#                          center_patch=config['center_patch'],\n",
    "#                          overlap_label=config['overlap_label_predict'],\n",
    "#                          final_val = True)\n",
    "#     mv_results(config['training_predict_dir'],config['training_to_upload'])\n",
    "#     print('Training dataset prediction finished.')\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-16T02:31:50.785Z"
    }
   },
   "outputs": [],
   "source": [
    "main_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:34:58.921497Z",
     "start_time": "2020-06-16T18:34:56.348643Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model\n"
     ]
    }
   ],
   "source": [
    "model = load_old_model(config[\"model_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T18:35:57.309925Z",
     "start_time": "2020-06-16T18:35:57.303919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
